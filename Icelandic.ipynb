{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHMpHVanxwTM",
        "outputId": "4540b522-2e42-4cdd-fb4b-545ccc096a4f"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# split a loaded document into sentences\n",
        "def to_pairs(doc):\n",
        "\tlines = doc.strip().split('\\n')\n",
        "\tpairs = [line.split('\\t') for line in  lines]\n",
        "\treturn pairs\n",
        "\n",
        "# clean a list of lines\n",
        "def clean_pairs(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\t#re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor pair in lines:\n",
        "\t\tclean_pair = list()\n",
        "\t\tfor line in pair:\n",
        "\t\t\t# normalize unicode characters\n",
        "\t\t\t#line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t\t#line = line.decode('UTF-8')\n",
        "\t\t\t# tokenize on white space\n",
        "\t\t\tline = line.split()\n",
        "\t\t\t# convert to lowercase\n",
        "\t\t\t#line = [word.lower() for word in line]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tline = [word.translate(table) for word in line]\n",
        "\t\t\t# remove non-printable chars form each token\n",
        "\t\t\t#line = [re_print.sub('', w) for w in line]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t#\tline = [word for word in line if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tclean_pair.append(' '.join(line))\n",
        "\t\tcleaned.append(clean_pair)\n",
        "\treturn array(cleaned)\n",
        "\n",
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)\n",
        "\n",
        "# load dataset\n",
        "filename = 'isl.txt'\n",
        "doc = load_doc(filename)\n",
        "# split into english-german pairs\n",
        "pairs = to_pairs(doc)\n",
        "# clean sentences\n",
        "clean_pairs = clean_pairs(pairs)\n",
        "# save clean pairs to file\n",
        "save_clean_data(clean_pairs, 'english-Icelandic.pkl')\n",
        "# spot check\n",
        "for i in range(100):\n",
        "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: english-Icelandic.pkl\n",
            "[Hi] => [Hæ]\n",
            "[Hi] => [Halló]\n",
            "[Run] => [Hlauptu]\n",
            "[Run] => [Hlaupið]\n",
            "[Hello] => [Halló]\n",
            "[Cheers] => [Skál]\n",
            "[Got it] => [Skilið]\n",
            "[He ran] => [Hann hljóp]\n",
            "[I know] => [Ég veit]\n",
            "[Im OK] => [Það er allt í lagi með mig]\n",
            "[Really] => [Virkilega]\n",
            "[Really] => [Er það satt]\n",
            "[Really] => [Í alvöru]\n",
            "[We try] => [Við reynum]\n",
            "[Why me] => [Af hverju ég]\n",
            "[Awesome] => [Frábært]\n",
            "[Get out] => [Komdu þér út]\n",
            "[Get out] => [Drullaðu þér út]\n",
            "[Get out] => [Hypjaðu þig út]\n",
            "[Go away] => [Farðu]\n",
            "[Go away] => [Farðu burt]\n",
            "[Go away] => [Farðu burt]\n",
            "[Go away] => [Farðu í burtu]\n",
            "[Goodbye] => [Bless]\n",
            "[Goodbye] => [Bæ]\n",
            "[Goodbye] => [Vertu sæll]\n",
            "[Goodbye] => [Vertu sæl]\n",
            "[Goodbye] => [Verið þið sæl]\n",
            "[Goodbye] => [Vertu blessaður]\n",
            "[Goodbye] => [Vertu blessuð]\n",
            "[Goodbye] => [Verið þið blessuð]\n",
            "[He runs] => [Hann hleypur]\n",
            "[Im sad] => [Ég er hrygg]\n",
            "[Im sad] => [Ég er hryggur]\n",
            "[Im sad] => [Ég er leið]\n",
            "[Im sad] => [Ég er leiður]\n",
            "[Its OK] => [Það er í lagi]\n",
            "[Its OK] => [Það er ókey]\n",
            "[Join us] => [Vertu með okkur]\n",
            "[Me too] => [Ég líka]\n",
            "[Open up] => [Opnaðu]\n",
            "[See you] => [Sjáumst]\n",
            "[Wake up] => [Vaknaðu]\n",
            "[Wash up] => [Þvoðu upp]\n",
            "[Why not] => [Af hverju ekki]\n",
            "[You run] => [Þú hleypur]\n",
            "[You run] => [Þið hlaupið]\n",
            "[Cheer up] => [Hresstu þig við]\n",
            "[Cheer up] => [Láttu ekki hugfallast]\n",
            "[Cool off] => [Róaðu þig]\n",
            "[Get away] => [Komdu þér í burtu]\n",
            "[Get down] => [Komdu þér niður]\n",
            "[Grab him] => [Náðu honum]\n",
            "[Have fun] => [Skemmtu þér vel]\n",
            "[He tries] => [Hann reynir]\n",
            "[Hurry up] => [Flýttu þér]\n",
            "[I use it] => [Ég nota hann]\n",
            "[I use it] => [Ég nota hana]\n",
            "[I use it] => [Ég nota það]\n",
            "[Ill pay] => [Ég skal borga]\n",
            "[Im busy] => [Ég er upptekin]\n",
            "[Im busy] => [Ég er upptekinn]\n",
            "[Im free] => [Ég er laus]\n",
            "[Im full] => [Ég er södd]\n",
            "[Im full] => [Ég er saddur]\n",
            "[Im poor] => [Ég er fátæk]\n",
            "[Im poor] => [Ég er fátækur]\n",
            "[Keep out] => [Aðgangur bannaður]\n",
            "[Stand up] => [Stattu á fætur]\n",
            "[Stand up] => [Stattu upp]\n",
            "[Stand up] => [Standið á fætur]\n",
            "[Stand up] => [Á fætur með þig]\n",
            "[Stand up] => [Á fætur með ykkur]\n",
            "[Too late] => [Of seint]\n",
            "[Who am I] => [Hver er ég]\n",
            "[Calm down] => [Róaðu þig]\n",
            "[Catch him] => [Náið honum]\n",
            "[Come here] => [Komdu hingað]\n",
            "[Come here] => [Komdu]\n",
            "[Come over] => [Komdu yfir]\n",
            "[Hes sexy] => [Hann er sexí]\n",
            "[I can run] => [Ég get hlaupið]\n",
            "[I give up] => [Ég gefst upp]\n",
            "[I hope so] => [Ég vona það]\n",
            "[I like it] => [Ég kann að meta það]\n",
            "[I mean it] => [Ég meina það]\n",
            "[Im awake] => [Ég er vakandi]\n",
            "[Im bored] => [Mér leiðist]\n",
            "[Im happy] => [Ég er glaður]\n",
            "[Im sorry] => [Fyrirgefðu]\n",
            "[Im sorry] => [Mér þykir fyrir því]\n",
            "[Im tired] => [Ég er þreitt]\n",
            "[Its 830] => [Klukkan er hálf níu]\n",
            "[Its cold] => [Það er kalt]\n",
            "[Of course] => [Auðvitað]\n",
            "[Of course] => [Auðvitað]\n",
            "[Try again] => [Reyndu aftur]\n",
            "[Am I wrong] => [Hef ég rangt fyrir mér]\n",
            "[Can I help] => [Get ég hjálpað]\n",
            "[Choose one] => [Veldu einn]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoaKu3vB01rP",
        "outputId": "3b26f4ab-bf32-4ea8-af58-a2d58e081191"
      },
      "source": [
        "from pickle import load\n",
        "from pickle import dump\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)\n",
        "\n",
        "# load dataset\n",
        "raw_dataset = load_clean_sentences('english-Icelandic.pkl')\n",
        "\n",
        "# reduce dataset size\n",
        "n_sentences = 6558\n",
        "dataset = raw_dataset[:n_sentences, :]\n",
        "# random shuffle\n",
        "shuffle(dataset)\n",
        "# split into train/test\n",
        "train, test = dataset[:6000], dataset[558:]\n",
        "# save\n",
        "save_clean_data(dataset, 'english-Icelandic-both.pkl')\n",
        "save_clean_data(train, 'english-Icelandic-train.pkl')\n",
        "save_clean_data(test, 'english-Icelandic-test.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: english-Icelandic-both.pkl\n",
            "Saved: english-Icelandic-train.pkl\n",
            "Saved: english-Icelandic-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDzC-L_c2nUj",
        "outputId": "84b23b68-5e26-476f-f9a8-a25a3ea92804"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "print('Icelandic Vocabulary Size: %d' % ger_vocab_size)\n",
        "print('Icelandic  Max Length: %d' % (ger_length))\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_output(trainY, eng_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_output(testY, eng_vocab_size)\n",
        "\n",
        "# define model\n",
        "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# fit model\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3624\n",
            "English Max Length: 38\n",
            "Icelandic Vocabulary Size: 6233\n",
            "Icelandic  Max Length: 35\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 35, 256)           1595648   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 38, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 38, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 38, 3624)          931368    \n",
            "=================================================================\n",
            "Total params: 3,577,640\n",
            "Trainable params: 3,577,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "79/79 - 115s - loss: 2.2583 - val_loss: 1.2101\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.21008, saving model to model.h5\n",
            "Epoch 2/100\n",
            "79/79 - 108s - loss: 1.2165 - val_loss: 1.2388\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.21008\n",
            "Epoch 3/100\n",
            "79/79 - 110s - loss: 1.2378 - val_loss: 1.2037\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21008 to 1.20366, saving model to model.h5\n",
            "Epoch 4/100\n",
            "79/79 - 108s - loss: 1.1528 - val_loss: 1.0526\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.20366 to 1.05262, saving model to model.h5\n",
            "Epoch 5/100\n",
            "79/79 - 110s - loss: 1.0533 - val_loss: 1.0343\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.05262 to 1.03426, saving model to model.h5\n",
            "Epoch 6/100\n",
            "79/79 - 109s - loss: 1.0340 - val_loss: 1.0268\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.03426 to 1.02683, saving model to model.h5\n",
            "Epoch 7/100\n",
            "79/79 - 115s - loss: 1.0223 - val_loss: 1.0230\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.02683 to 1.02298, saving model to model.h5\n",
            "Epoch 8/100\n",
            "79/79 - 116s - loss: 1.0141 - val_loss: 1.0091\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.02298 to 1.00906, saving model to model.h5\n",
            "Epoch 9/100\n",
            "79/79 - 112s - loss: 1.0021 - val_loss: 1.0005\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.00906 to 1.00048, saving model to model.h5\n",
            "Epoch 10/100\n",
            "79/79 - 111s - loss: 0.9911 - val_loss: 0.9959\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.00048 to 0.99594, saving model to model.h5\n",
            "Epoch 11/100\n",
            "79/79 - 111s - loss: 0.9850 - val_loss: 0.9945\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.99594 to 0.99446, saving model to model.h5\n",
            "Epoch 12/100\n",
            "79/79 - 110s - loss: 0.9770 - val_loss: 0.9868\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.99446 to 0.98677, saving model to model.h5\n",
            "Epoch 13/100\n",
            "79/79 - 107s - loss: 0.9710 - val_loss: 0.9842\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.98677 to 0.98423, saving model to model.h5\n",
            "Epoch 14/100\n",
            "79/79 - 109s - loss: 0.9647 - val_loss: 0.9797\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.98423 to 0.97965, saving model to model.h5\n",
            "Epoch 15/100\n",
            "79/79 - 108s - loss: 0.9585 - val_loss: 0.9759\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.97965 to 0.97594, saving model to model.h5\n",
            "Epoch 16/100\n",
            "79/79 - 108s - loss: 0.9544 - val_loss: 0.9729\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.97594 to 0.97294, saving model to model.h5\n",
            "Epoch 17/100\n",
            "79/79 - 108s - loss: 0.9492 - val_loss: 0.9696\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.97294 to 0.96961, saving model to model.h5\n",
            "Epoch 18/100\n",
            "79/79 - 109s - loss: 0.9414 - val_loss: 0.9664\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.96961 to 0.96643, saving model to model.h5\n",
            "Epoch 19/100\n",
            "79/79 - 109s - loss: 0.9350 - val_loss: 0.9613\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.96643 to 0.96129, saving model to model.h5\n",
            "Epoch 20/100\n",
            "79/79 - 109s - loss: 0.9277 - val_loss: 0.9590\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.96129 to 0.95902, saving model to model.h5\n",
            "Epoch 21/100\n",
            "79/79 - 109s - loss: 0.9234 - val_loss: 0.9561\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.95902 to 0.95610, saving model to model.h5\n",
            "Epoch 22/100\n",
            "79/79 - 110s - loss: 0.9168 - val_loss: 0.9627\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.95610\n",
            "Epoch 23/100\n",
            "79/79 - 107s - loss: 0.9111 - val_loss: 0.9417\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.95610 to 0.94174, saving model to model.h5\n",
            "Epoch 24/100\n",
            "79/79 - 107s - loss: 0.9002 - val_loss: 0.9371\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.94174 to 0.93712, saving model to model.h5\n",
            "Epoch 25/100\n",
            "79/79 - 107s - loss: 0.8903 - val_loss: 0.9316\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.93712 to 0.93162, saving model to model.h5\n",
            "Epoch 26/100\n",
            "79/79 - 106s - loss: 0.8854 - val_loss: 0.9461\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.93162\n",
            "Epoch 27/100\n",
            "79/79 - 106s - loss: 0.8777 - val_loss: 0.9207\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.93162 to 0.92074, saving model to model.h5\n",
            "Epoch 28/100\n",
            "79/79 - 107s - loss: 0.8668 - val_loss: 0.9126\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.92074 to 0.91261, saving model to model.h5\n",
            "Epoch 29/100\n",
            "79/79 - 106s - loss: 0.8565 - val_loss: 0.9056\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.91261 to 0.90561, saving model to model.h5\n",
            "Epoch 30/100\n",
            "79/79 - 110s - loss: 0.8464 - val_loss: 0.9093\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.90561\n",
            "Epoch 31/100\n",
            "79/79 - 113s - loss: 0.8375 - val_loss: 0.8894\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.90561 to 0.88941, saving model to model.h5\n",
            "Epoch 32/100\n",
            "79/79 - 110s - loss: 0.8263 - val_loss: 0.8994\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.88941\n",
            "Epoch 33/100\n",
            "79/79 - 110s - loss: 0.8197 - val_loss: 0.8754\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.88941 to 0.87543, saving model to model.h5\n",
            "Epoch 34/100\n",
            "79/79 - 109s - loss: 0.8081 - val_loss: 0.8686\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.87543 to 0.86859, saving model to model.h5\n",
            "Epoch 35/100\n",
            "79/79 - 109s - loss: 0.7940 - val_loss: 0.8565\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.86859 to 0.85647, saving model to model.h5\n",
            "Epoch 36/100\n",
            "79/79 - 109s - loss: 0.7804 - val_loss: 0.8473\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.85647 to 0.84732, saving model to model.h5\n",
            "Epoch 37/100\n",
            "79/79 - 108s - loss: 0.7681 - val_loss: 0.8394\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.84732 to 0.83942, saving model to model.h5\n",
            "Epoch 38/100\n",
            "79/79 - 107s - loss: 0.7541 - val_loss: 0.8322\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.83942 to 0.83221, saving model to model.h5\n",
            "Epoch 39/100\n",
            "79/79 - 107s - loss: 0.7423 - val_loss: 0.8162\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.83221 to 0.81615, saving model to model.h5\n",
            "Epoch 40/100\n",
            "79/79 - 106s - loss: 0.7251 - val_loss: 0.8051\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.81615 to 0.80515, saving model to model.h5\n",
            "Epoch 41/100\n",
            "79/79 - 107s - loss: 0.7106 - val_loss: 0.7896\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.80515 to 0.78962, saving model to model.h5\n",
            "Epoch 42/100\n",
            "79/79 - 107s - loss: 0.6944 - val_loss: 0.7756\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.78962 to 0.77555, saving model to model.h5\n",
            "Epoch 43/100\n",
            "79/79 - 107s - loss: 0.6760 - val_loss: 0.7633\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.77555 to 0.76333, saving model to model.h5\n",
            "Epoch 44/100\n",
            "79/79 - 108s - loss: 0.6582 - val_loss: 0.7569\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.76333 to 0.75693, saving model to model.h5\n",
            "Epoch 45/100\n",
            "79/79 - 107s - loss: 0.6473 - val_loss: 0.7407\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.75693 to 0.74069, saving model to model.h5\n",
            "Epoch 46/100\n",
            "79/79 - 107s - loss: 0.6279 - val_loss: 0.7242\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.74069 to 0.72417, saving model to model.h5\n",
            "Epoch 47/100\n",
            "79/79 - 108s - loss: 0.6094 - val_loss: 0.7151\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.72417 to 0.71508, saving model to model.h5\n",
            "Epoch 48/100\n",
            "79/79 - 107s - loss: 0.5957 - val_loss: 0.7061\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.71508 to 0.70612, saving model to model.h5\n",
            "Epoch 49/100\n",
            "79/79 - 108s - loss: 0.5816 - val_loss: 0.7002\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.70612 to 0.70017, saving model to model.h5\n",
            "Epoch 50/100\n",
            "79/79 - 108s - loss: 0.5664 - val_loss: 0.6880\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.70017 to 0.68799, saving model to model.h5\n",
            "Epoch 51/100\n",
            "79/79 - 107s - loss: 0.5508 - val_loss: 0.6723\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.68799 to 0.67225, saving model to model.h5\n",
            "Epoch 52/100\n",
            "79/79 - 108s - loss: 0.5378 - val_loss: 0.6678\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.67225 to 0.66777, saving model to model.h5\n",
            "Epoch 53/100\n",
            "79/79 - 108s - loss: 0.5283 - val_loss: 0.6638\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.66777 to 0.66382, saving model to model.h5\n",
            "Epoch 54/100\n",
            "79/79 - 108s - loss: 0.5147 - val_loss: 0.6479\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.66382 to 0.64794, saving model to model.h5\n",
            "Epoch 55/100\n",
            "79/79 - 107s - loss: 0.4978 - val_loss: 0.6334\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.64794 to 0.63342, saving model to model.h5\n",
            "Epoch 56/100\n",
            "79/79 - 109s - loss: 0.4832 - val_loss: 0.6284\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.63342 to 0.62843, saving model to model.h5\n",
            "Epoch 57/100\n",
            "79/79 - 108s - loss: 0.4687 - val_loss: 0.6233\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.62843 to 0.62334, saving model to model.h5\n",
            "Epoch 58/100\n",
            "79/79 - 109s - loss: 0.4554 - val_loss: 0.6081\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.62334 to 0.60813, saving model to model.h5\n",
            "Epoch 59/100\n",
            "79/79 - 110s - loss: 0.4406 - val_loss: 0.6009\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.60813 to 0.60088, saving model to model.h5\n",
            "Epoch 60/100\n",
            "79/79 - 109s - loss: 0.4287 - val_loss: 0.5962\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.60088 to 0.59621, saving model to model.h5\n",
            "Epoch 61/100\n",
            "79/79 - 109s - loss: 0.4175 - val_loss: 0.5868\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.59621 to 0.58681, saving model to model.h5\n",
            "Epoch 62/100\n",
            "79/79 - 108s - loss: 0.4047 - val_loss: 0.5730\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.58681 to 0.57302, saving model to model.h5\n",
            "Epoch 63/100\n",
            "79/79 - 108s - loss: 0.3911 - val_loss: 0.5679\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.57302 to 0.56791, saving model to model.h5\n",
            "Epoch 64/100\n",
            "79/79 - 109s - loss: 0.3807 - val_loss: 0.5640\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.56791 to 0.56404, saving model to model.h5\n",
            "Epoch 65/100\n",
            "79/79 - 107s - loss: 0.3704 - val_loss: 0.5552\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.56404 to 0.55525, saving model to model.h5\n",
            "Epoch 66/100\n",
            "79/79 - 107s - loss: 0.3584 - val_loss: 0.5475\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.55525 to 0.54753, saving model to model.h5\n",
            "Epoch 67/100\n",
            "79/79 - 107s - loss: 0.3505 - val_loss: 0.5458\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.54753 to 0.54583, saving model to model.h5\n",
            "Epoch 68/100\n",
            "79/79 - 106s - loss: 0.3391 - val_loss: 0.5313\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.54583 to 0.53129, saving model to model.h5\n",
            "Epoch 69/100\n",
            "79/79 - 108s - loss: 0.3246 - val_loss: 0.5243\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.53129 to 0.52427, saving model to model.h5\n",
            "Epoch 70/100\n",
            "79/79 - 108s - loss: 0.3139 - val_loss: 0.5173\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.52427 to 0.51733, saving model to model.h5\n",
            "Epoch 71/100\n",
            "79/79 - 106s - loss: 0.3032 - val_loss: 0.5119\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.51733 to 0.51193, saving model to model.h5\n",
            "Epoch 72/100\n",
            "79/79 - 108s - loss: 0.2931 - val_loss: 0.5052\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.51193 to 0.50520, saving model to model.h5\n",
            "Epoch 73/100\n",
            "79/79 - 108s - loss: 0.2840 - val_loss: 0.5054\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.50520\n",
            "Epoch 74/100\n",
            "79/79 - 107s - loss: 0.3606 - val_loss: 0.5235\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.50520\n",
            "Epoch 75/100\n",
            "79/79 - 107s - loss: 0.3021 - val_loss: 0.5012\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.50520 to 0.50117, saving model to model.h5\n",
            "Epoch 76/100\n",
            "79/79 - 107s - loss: 0.2773 - val_loss: 0.4933\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.50117 to 0.49330, saving model to model.h5\n",
            "Epoch 77/100\n",
            "79/79 - 108s - loss: 0.2599 - val_loss: 0.4788\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.49330 to 0.47882, saving model to model.h5\n",
            "Epoch 78/100\n",
            "79/79 - 108s - loss: 0.2444 - val_loss: 0.4709\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.47882 to 0.47090, saving model to model.h5\n",
            "Epoch 79/100\n",
            "79/79 - 108s - loss: 0.2355 - val_loss: 0.4715\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.47090\n",
            "Epoch 80/100\n",
            "79/79 - 107s - loss: 0.2322 - val_loss: 0.4794\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.47090\n",
            "Epoch 81/100\n",
            "79/79 - 109s - loss: 0.2291 - val_loss: 0.4636\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.47090 to 0.46356, saving model to model.h5\n",
            "Epoch 82/100\n",
            "79/79 - 108s - loss: 0.2174 - val_loss: 0.4561\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.46356 to 0.45609, saving model to model.h5\n",
            "Epoch 83/100\n",
            "79/79 - 108s - loss: 0.2083 - val_loss: 0.4552\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.45609 to 0.45517, saving model to model.h5\n",
            "Epoch 84/100\n",
            "79/79 - 109s - loss: 0.2046 - val_loss: 0.4499\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.45517 to 0.44990, saving model to model.h5\n",
            "Epoch 85/100\n",
            "79/79 - 109s - loss: 0.1934 - val_loss: 0.4448\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.44990 to 0.44482, saving model to model.h5\n",
            "Epoch 86/100\n",
            "79/79 - 108s - loss: 0.1864 - val_loss: 0.4411\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.44482 to 0.44108, saving model to model.h5\n",
            "Epoch 87/100\n",
            "79/79 - 108s - loss: 0.1796 - val_loss: 0.4407\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.44108 to 0.44073, saving model to model.h5\n",
            "Epoch 88/100\n",
            "79/79 - 108s - loss: 0.1755 - val_loss: 0.4363\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.44073 to 0.43633, saving model to model.h5\n",
            "Epoch 89/100\n",
            "79/79 - 109s - loss: 0.1709 - val_loss: 0.4381\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.43633\n",
            "Epoch 90/100\n",
            "79/79 - 108s - loss: 0.1673 - val_loss: 0.4332\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.43633 to 0.43319, saving model to model.h5\n",
            "Epoch 91/100\n",
            "79/79 - 108s - loss: 0.1615 - val_loss: 0.4278\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.43319 to 0.42777, saving model to model.h5\n",
            "Epoch 92/100\n",
            "79/79 - 108s - loss: 0.1538 - val_loss: 0.4253\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.42777 to 0.42530, saving model to model.h5\n",
            "Epoch 93/100\n",
            "79/79 - 109s - loss: 0.1477 - val_loss: 0.4239\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.42530 to 0.42385, saving model to model.h5\n",
            "Epoch 94/100\n",
            "79/79 - 109s - loss: 0.1447 - val_loss: 0.4394\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.42385\n",
            "Epoch 95/100\n",
            "79/79 - 107s - loss: 0.1472 - val_loss: 0.4299\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.42385\n",
            "Epoch 96/100\n",
            "79/79 - 107s - loss: 0.1407 - val_loss: 0.4207\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.42385 to 0.42068, saving model to model.h5\n",
            "Epoch 97/100\n",
            "79/79 - 108s - loss: 0.1320 - val_loss: 0.4136\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.42068 to 0.41363, saving model to model.h5\n",
            "Epoch 98/100\n",
            "79/79 - 108s - loss: 0.1243 - val_loss: 0.4169\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.41363\n",
            "Epoch 99/100\n",
            "79/79 - 108s - loss: 0.1235 - val_loss: 0.4159\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.41363\n",
            "Epoch 100/100\n",
            "79/79 - 108s - loss: 0.1263 - val_loss: 0.4136\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.41363 to 0.41356, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8bb7201950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgZCNE98bh-q",
        "outputId": "54e2616b-a8cf-494d-8d88-9f78faccda43"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "print('Icelandic Vocabulary Size: %d' % ger_vocab_size)\n",
        "print('Icelandic  Max Length: %d' % (ger_length))\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_output(trainY, eng_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_output(testY, eng_vocab_size)\n",
        "\n",
        "# define model\n",
        "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# fit model\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3624\n",
            "English Max Length: 38\n",
            "Icelandic Vocabulary Size: 6233\n",
            "Icelandic  Max Length: 35\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 35, 256)           1595648   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 38, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 38, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 38, 3624)          931368    \n",
            "=================================================================\n",
            "Total params: 3,577,640\n",
            "Trainable params: 3,577,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "94/94 - 97s - loss: 2.1009 - val_loss: 1.2225\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.22248, saving model to model.h5\n",
            "Epoch 2/200\n",
            "94/94 - 91s - loss: 1.1988 - val_loss: 1.1773\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.22248 to 1.17734, saving model to model.h5\n",
            "Epoch 3/200\n",
            "94/94 - 90s - loss: 1.1771 - val_loss: 1.1392\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.17734 to 1.13920, saving model to model.h5\n",
            "Epoch 4/200\n",
            "94/94 - 91s - loss: 1.0901 - val_loss: 1.0318\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.13920 to 1.03184, saving model to model.h5\n",
            "Epoch 5/200\n",
            "94/94 - 91s - loss: 1.0390 - val_loss: 1.0172\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.03184 to 1.01718, saving model to model.h5\n",
            "Epoch 6/200\n",
            "94/94 - 91s - loss: 1.0245 - val_loss: 1.0076\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.01718 to 1.00760, saving model to model.h5\n",
            "Epoch 7/200\n",
            "94/94 - 90s - loss: 1.0135 - val_loss: 0.9959\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.00760 to 0.99585, saving model to model.h5\n",
            "Epoch 8/200\n",
            "94/94 - 91s - loss: 1.0027 - val_loss: 0.9881\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.99585 to 0.98814, saving model to model.h5\n",
            "Epoch 9/200\n",
            "94/94 - 91s - loss: 0.9936 - val_loss: 0.9795\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.98814 to 0.97951, saving model to model.h5\n",
            "Epoch 10/200\n",
            "94/94 - 91s - loss: 0.9835 - val_loss: 0.9747\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.97951 to 0.97475, saving model to model.h5\n",
            "Epoch 11/200\n",
            "94/94 - 91s - loss: 0.9757 - val_loss: 0.9652\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.97475 to 0.96525, saving model to model.h5\n",
            "Epoch 12/200\n",
            "94/94 - 91s - loss: 0.9679 - val_loss: 0.9598\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.96525 to 0.95975, saving model to model.h5\n",
            "Epoch 13/200\n",
            "94/94 - 89s - loss: 0.9628 - val_loss: 0.9541\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.95975 to 0.95411, saving model to model.h5\n",
            "Epoch 14/200\n",
            "94/94 - 89s - loss: 0.9567 - val_loss: 0.9507\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.95411 to 0.95073, saving model to model.h5\n",
            "Epoch 15/200\n",
            "94/94 - 89s - loss: 0.9501 - val_loss: 0.9463\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.95073 to 0.94626, saving model to model.h5\n",
            "Epoch 16/200\n",
            "94/94 - 89s - loss: 0.9428 - val_loss: 0.9356\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.94626 to 0.93558, saving model to model.h5\n",
            "Epoch 17/200\n",
            "94/94 - 89s - loss: 0.9333 - val_loss: 0.9311\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.93558 to 0.93107, saving model to model.h5\n",
            "Epoch 18/200\n",
            "94/94 - 89s - loss: 0.9262 - val_loss: 0.9224\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.93107 to 0.92243, saving model to model.h5\n",
            "Epoch 19/200\n",
            "94/94 - 89s - loss: 0.9187 - val_loss: 0.9199\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.92243 to 0.91989, saving model to model.h5\n",
            "Epoch 20/200\n",
            "94/94 - 89s - loss: 0.9080 - val_loss: 0.9003\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.91989 to 0.90031, saving model to model.h5\n",
            "Epoch 21/200\n",
            "94/94 - 89s - loss: 0.8985 - val_loss: 0.8889\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.90031 to 0.88894, saving model to model.h5\n",
            "Epoch 22/200\n",
            "94/94 - 90s - loss: 0.8867 - val_loss: 0.8798\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.88894 to 0.87984, saving model to model.h5\n",
            "Epoch 23/200\n",
            "94/94 - 90s - loss: 0.8747 - val_loss: 0.8756\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.87984 to 0.87557, saving model to model.h5\n",
            "Epoch 24/200\n",
            "94/94 - 90s - loss: 0.8667 - val_loss: 0.8600\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.87557 to 0.86002, saving model to model.h5\n",
            "Epoch 25/200\n",
            "94/94 - 89s - loss: 0.8566 - val_loss: 0.8498\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.86002 to 0.84981, saving model to model.h5\n",
            "Epoch 26/200\n",
            "94/94 - 90s - loss: 0.8427 - val_loss: 0.8408\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.84981 to 0.84083, saving model to model.h5\n",
            "Epoch 27/200\n",
            "94/94 - 89s - loss: 0.8282 - val_loss: 0.8262\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.84083 to 0.82615, saving model to model.h5\n",
            "Epoch 28/200\n",
            "94/94 - 90s - loss: 0.8149 - val_loss: 0.8105\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.82615 to 0.81049, saving model to model.h5\n",
            "Epoch 29/200\n",
            "94/94 - 91s - loss: 0.7979 - val_loss: 0.7962\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.81049 to 0.79625, saving model to model.h5\n",
            "Epoch 30/200\n",
            "94/94 - 90s - loss: 0.7807 - val_loss: 0.7777\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.79625 to 0.77770, saving model to model.h5\n",
            "Epoch 31/200\n",
            "94/94 - 91s - loss: 0.7627 - val_loss: 0.7613\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.77770 to 0.76125, saving model to model.h5\n",
            "Epoch 32/200\n",
            "94/94 - 91s - loss: 0.7476 - val_loss: 0.7459\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.76125 to 0.74591, saving model to model.h5\n",
            "Epoch 33/200\n",
            "94/94 - 90s - loss: 0.7306 - val_loss: 0.7286\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.74591 to 0.72859, saving model to model.h5\n",
            "Epoch 34/200\n",
            "94/94 - 89s - loss: 0.7089 - val_loss: 0.7098\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.72859 to 0.70980, saving model to model.h5\n",
            "Epoch 35/200\n",
            "94/94 - 90s - loss: 0.6908 - val_loss: 0.6896\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.70980 to 0.68965, saving model to model.h5\n",
            "Epoch 36/200\n",
            "94/94 - 90s - loss: 0.6727 - val_loss: 0.6730\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.68965 to 0.67299, saving model to model.h5\n",
            "Epoch 37/200\n",
            "94/94 - 90s - loss: 0.6526 - val_loss: 0.6567\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.67299 to 0.65670, saving model to model.h5\n",
            "Epoch 38/200\n",
            "94/94 - 90s - loss: 0.6335 - val_loss: 0.6379\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.65670 to 0.63787, saving model to model.h5\n",
            "Epoch 39/200\n",
            "94/94 - 89s - loss: 0.6169 - val_loss: 0.6314\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.63787 to 0.63140, saving model to model.h5\n",
            "Epoch 40/200\n",
            "94/94 - 90s - loss: 0.6050 - val_loss: 0.6103\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.63140 to 0.61033, saving model to model.h5\n",
            "Epoch 41/200\n",
            "94/94 - 90s - loss: 0.5855 - val_loss: 0.5922\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.61033 to 0.59216, saving model to model.h5\n",
            "Epoch 42/200\n",
            "94/94 - 90s - loss: 0.5643 - val_loss: 0.5732\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.59216 to 0.57322, saving model to model.h5\n",
            "Epoch 43/200\n",
            "94/94 - 90s - loss: 0.5457 - val_loss: 0.5587\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.57322 to 0.55873, saving model to model.h5\n",
            "Epoch 44/200\n",
            "94/94 - 90s - loss: 0.5284 - val_loss: 0.5432\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.55873 to 0.54315, saving model to model.h5\n",
            "Epoch 45/200\n",
            "94/94 - 90s - loss: 0.5132 - val_loss: 0.5283\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.54315 to 0.52829, saving model to model.h5\n",
            "Epoch 46/200\n",
            "94/94 - 90s - loss: 0.4974 - val_loss: 0.5120\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.52829 to 0.51197, saving model to model.h5\n",
            "Epoch 47/200\n",
            "94/94 - 90s - loss: 0.4839 - val_loss: 0.5009\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.51197 to 0.50092, saving model to model.h5\n",
            "Epoch 48/200\n",
            "94/94 - 90s - loss: 0.4681 - val_loss: 0.4882\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.50092 to 0.48823, saving model to model.h5\n",
            "Epoch 49/200\n",
            "94/94 - 90s - loss: 0.4546 - val_loss: 0.4765\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.48823 to 0.47654, saving model to model.h5\n",
            "Epoch 50/200\n",
            "94/94 - 90s - loss: 0.4406 - val_loss: 0.4612\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.47654 to 0.46118, saving model to model.h5\n",
            "Epoch 51/200\n",
            "94/94 - 89s - loss: 0.4238 - val_loss: 0.4529\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.46118 to 0.45292, saving model to model.h5\n",
            "Epoch 52/200\n",
            "94/94 - 89s - loss: 0.4137 - val_loss: 0.4376\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.45292 to 0.43758, saving model to model.h5\n",
            "Epoch 53/200\n",
            "94/94 - 90s - loss: 0.3978 - val_loss: 0.4286\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.43758 to 0.42859, saving model to model.h5\n",
            "Epoch 54/200\n",
            "94/94 - 89s - loss: 0.3829 - val_loss: 0.4193\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.42859 to 0.41934, saving model to model.h5\n",
            "Epoch 55/200\n",
            "94/94 - 90s - loss: 0.3724 - val_loss: 0.4043\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.41934 to 0.40429, saving model to model.h5\n",
            "Epoch 56/200\n",
            "94/94 - 90s - loss: 0.3587 - val_loss: 0.3915\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.40429 to 0.39152, saving model to model.h5\n",
            "Epoch 57/200\n",
            "94/94 - 90s - loss: 0.3450 - val_loss: 0.3828\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.39152 to 0.38285, saving model to model.h5\n",
            "Epoch 58/200\n",
            "94/94 - 89s - loss: 0.3365 - val_loss: 0.3732\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.38285 to 0.37320, saving model to model.h5\n",
            "Epoch 59/200\n",
            "94/94 - 90s - loss: 0.3282 - val_loss: 0.3696\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.37320 to 0.36959, saving model to model.h5\n",
            "Epoch 60/200\n",
            "94/94 - 90s - loss: 0.3155 - val_loss: 0.3556\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.36959 to 0.35558, saving model to model.h5\n",
            "Epoch 61/200\n",
            "94/94 - 90s - loss: 0.3014 - val_loss: 0.3437\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.35558 to 0.34374, saving model to model.h5\n",
            "Epoch 62/200\n",
            "94/94 - 89s - loss: 0.2890 - val_loss: 0.3343\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.34374 to 0.33429, saving model to model.h5\n",
            "Epoch 63/200\n",
            "94/94 - 91s - loss: 0.2799 - val_loss: 0.3270\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.33429 to 0.32700, saving model to model.h5\n",
            "Epoch 64/200\n",
            "94/94 - 91s - loss: 0.2743 - val_loss: 0.3208\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.32700 to 0.32077, saving model to model.h5\n",
            "Epoch 65/200\n",
            "94/94 - 90s - loss: 0.2644 - val_loss: 0.3090\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.32077 to 0.30898, saving model to model.h5\n",
            "Epoch 66/200\n",
            "94/94 - 91s - loss: 0.2522 - val_loss: 0.3036\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.30898 to 0.30364, saving model to model.h5\n",
            "Epoch 67/200\n",
            "94/94 - 91s - loss: 0.2444 - val_loss: 0.2965\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.30364 to 0.29648, saving model to model.h5\n",
            "Epoch 68/200\n",
            "94/94 - 91s - loss: 0.2375 - val_loss: 0.2898\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.29648 to 0.28985, saving model to model.h5\n",
            "Epoch 69/200\n",
            "94/94 - 91s - loss: 0.2309 - val_loss: 0.2869\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.28985 to 0.28695, saving model to model.h5\n",
            "Epoch 70/200\n",
            "94/94 - 91s - loss: 0.2229 - val_loss: 0.2804\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.28695 to 0.28036, saving model to model.h5\n",
            "Epoch 71/200\n",
            "94/94 - 91s - loss: 0.2142 - val_loss: 0.2815\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.28036\n",
            "Epoch 72/200\n",
            "94/94 - 91s - loss: 0.2087 - val_loss: 0.2619\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.28036 to 0.26187, saving model to model.h5\n",
            "Epoch 73/200\n",
            "94/94 - 90s - loss: 0.2027 - val_loss: 0.2596\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.26187 to 0.25959, saving model to model.h5\n",
            "Epoch 74/200\n",
            "94/94 - 91s - loss: 0.1949 - val_loss: 0.2527\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.25959 to 0.25269, saving model to model.h5\n",
            "Epoch 75/200\n",
            "94/94 - 90s - loss: 0.1861 - val_loss: 0.2472\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.25269 to 0.24719, saving model to model.h5\n",
            "Epoch 76/200\n",
            "94/94 - 90s - loss: 0.1797 - val_loss: 0.2419\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.24719 to 0.24188, saving model to model.h5\n",
            "Epoch 77/200\n",
            "94/94 - 90s - loss: 0.1718 - val_loss: 0.2340\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.24188 to 0.23401, saving model to model.h5\n",
            "Epoch 78/200\n",
            "94/94 - 90s - loss: 0.1650 - val_loss: 0.2319\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.23401 to 0.23185, saving model to model.h5\n",
            "Epoch 79/200\n",
            "94/94 - 90s - loss: 0.1617 - val_loss: 0.2314\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.23185 to 0.23136, saving model to model.h5\n",
            "Epoch 80/200\n",
            "94/94 - 90s - loss: 0.1587 - val_loss: 0.2256\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.23136 to 0.22560, saving model to model.h5\n",
            "Epoch 81/200\n",
            "94/94 - 90s - loss: 0.1539 - val_loss: 0.2194\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.22560 to 0.21942, saving model to model.h5\n",
            "Epoch 82/200\n",
            "94/94 - 90s - loss: 0.1483 - val_loss: 0.2175\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.21942 to 0.21750, saving model to model.h5\n",
            "Epoch 83/200\n",
            "94/94 - 90s - loss: 0.1421 - val_loss: 0.2094\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.21750 to 0.20945, saving model to model.h5\n",
            "Epoch 84/200\n",
            "94/94 - 90s - loss: 0.1338 - val_loss: 0.2031\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.20945 to 0.20307, saving model to model.h5\n",
            "Epoch 85/200\n",
            "94/94 - 90s - loss: 0.1274 - val_loss: 0.2004\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.20307 to 0.20039, saving model to model.h5\n",
            "Epoch 86/200\n",
            "94/94 - 90s - loss: 0.1237 - val_loss: 0.1965\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.20039 to 0.19651, saving model to model.h5\n",
            "Epoch 87/200\n",
            "94/94 - 90s - loss: 0.1198 - val_loss: 0.1937\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.19651 to 0.19373, saving model to model.h5\n",
            "Epoch 88/200\n",
            "94/94 - 90s - loss: 0.1175 - val_loss: 0.1913\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.19373 to 0.19128, saving model to model.h5\n",
            "Epoch 89/200\n",
            "94/94 - 90s - loss: 0.1148 - val_loss: 0.1955\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.19128\n",
            "Epoch 90/200\n",
            "94/94 - 90s - loss: 0.1258 - val_loss: 0.2057\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.19128\n",
            "Epoch 91/200\n",
            "94/94 - 89s - loss: 0.1235 - val_loss: 0.1964\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.19128\n",
            "Epoch 92/200\n",
            "94/94 - 89s - loss: 0.1111 - val_loss: 0.1821\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.19128 to 0.18213, saving model to model.h5\n",
            "Epoch 93/200\n",
            "94/94 - 89s - loss: 0.0997 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.18213 to 0.17521, saving model to model.h5\n",
            "Epoch 94/200\n",
            "94/94 - 90s - loss: 0.0931 - val_loss: 0.1737\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.17521 to 0.17374, saving model to model.h5\n",
            "Epoch 95/200\n",
            "94/94 - 89s - loss: 0.0913 - val_loss: 0.1726\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.17374 to 0.17256, saving model to model.h5\n",
            "Epoch 96/200\n",
            "94/94 - 89s - loss: 0.0878 - val_loss: 0.1658\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.17256 to 0.16579, saving model to model.h5\n",
            "Epoch 97/200\n",
            "94/94 - 89s - loss: 0.0842 - val_loss: 0.1686\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.16579\n",
            "Epoch 98/200\n",
            "94/94 - 89s - loss: 0.0818 - val_loss: 0.1627\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.16579 to 0.16274, saving model to model.h5\n",
            "Epoch 99/200\n",
            "94/94 - 89s - loss: 0.0781 - val_loss: 0.1617\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.16274 to 0.16174, saving model to model.h5\n",
            "Epoch 100/200\n",
            "94/94 - 90s - loss: 0.0804 - val_loss: 0.1707\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.16174\n",
            "Epoch 101/200\n",
            "94/94 - 90s - loss: 0.0856 - val_loss: 0.1666\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.16174\n",
            "Epoch 102/200\n",
            "94/94 - 90s - loss: 0.0808 - val_loss: 0.1623\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.16174\n",
            "Epoch 103/200\n",
            "94/94 - 90s - loss: 0.0766 - val_loss: 0.1611\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.16174 to 0.16110, saving model to model.h5\n",
            "Epoch 104/200\n",
            "94/94 - 90s - loss: 0.0725 - val_loss: 0.1551\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.16110 to 0.15506, saving model to model.h5\n",
            "Epoch 105/200\n",
            "94/94 - 90s - loss: 0.0672 - val_loss: 0.1543\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.15506 to 0.15427, saving model to model.h5\n",
            "Epoch 106/200\n",
            "94/94 - 90s - loss: 0.0671 - val_loss: 0.1573\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.15427\n",
            "Epoch 107/200\n",
            "94/94 - 90s - loss: 0.0671 - val_loss: 0.1559\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.15427\n",
            "Epoch 108/200\n",
            "94/94 - 90s - loss: 0.0669 - val_loss: 0.1527\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.15427 to 0.15272, saving model to model.h5\n",
            "Epoch 109/200\n",
            "94/94 - 91s - loss: 0.0601 - val_loss: 0.1469\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.15272 to 0.14693, saving model to model.h5\n",
            "Epoch 110/200\n",
            "94/94 - 89s - loss: 0.0556 - val_loss: 0.1438\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.14693 to 0.14377, saving model to model.h5\n",
            "Epoch 111/200\n",
            "94/94 - 90s - loss: 0.0532 - val_loss: 0.1430\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.14377 to 0.14303, saving model to model.h5\n",
            "Epoch 112/200\n",
            "94/94 - 91s - loss: 0.0504 - val_loss: 0.1432\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.14303\n",
            "Epoch 113/200\n",
            "94/94 - 91s - loss: 0.0499 - val_loss: 0.1406\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.14303 to 0.14056, saving model to model.h5\n",
            "Epoch 114/200\n",
            "94/94 - 91s - loss: 0.0482 - val_loss: 0.1422\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.14056\n",
            "Epoch 115/200\n",
            "94/94 - 90s - loss: 0.0498 - val_loss: 0.1447\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.14056\n",
            "Epoch 116/200\n",
            "94/94 - 90s - loss: 0.0490 - val_loss: 0.1413\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.14056\n",
            "Epoch 117/200\n",
            "94/94 - 90s - loss: 0.0492 - val_loss: 0.1426\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.14056\n",
            "Epoch 118/200\n",
            "94/94 - 90s - loss: 0.0521 - val_loss: 0.1457\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.14056\n",
            "Epoch 119/200\n",
            "94/94 - 90s - loss: 0.0529 - val_loss: 0.1452\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.14056\n",
            "Epoch 120/200\n",
            "94/94 - 90s - loss: 0.0507 - val_loss: 0.1424\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.14056\n",
            "Epoch 121/200\n",
            "94/94 - 90s - loss: 0.0485 - val_loss: 0.1408\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.14056\n",
            "Epoch 122/200\n",
            "94/94 - 91s - loss: 0.0466 - val_loss: 0.1396\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.14056 to 0.13956, saving model to model.h5\n",
            "Epoch 123/200\n",
            "94/94 - 90s - loss: 0.0434 - val_loss: 0.1349\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.13956 to 0.13492, saving model to model.h5\n",
            "Epoch 124/200\n",
            "94/94 - 90s - loss: 0.0383 - val_loss: 0.1332\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.13492 to 0.13323, saving model to model.h5\n",
            "Epoch 125/200\n",
            "94/94 - 91s - loss: 0.0355 - val_loss: 0.1313\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.13323 to 0.13126, saving model to model.h5\n",
            "Epoch 126/200\n",
            "94/94 - 90s - loss: 0.0336 - val_loss: 0.1311\n",
            "\n",
            "Epoch 00126: val_loss improved from 0.13126 to 0.13107, saving model to model.h5\n",
            "Epoch 127/200\n",
            "94/94 - 90s - loss: 0.0327 - val_loss: 0.1285\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.13107 to 0.12852, saving model to model.h5\n",
            "Epoch 128/200\n",
            "94/94 - 91s - loss: 0.0323 - val_loss: 0.1288\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.12852\n",
            "Epoch 129/200\n",
            "94/94 - 91s - loss: 0.0330 - val_loss: 0.1335\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.12852\n",
            "Epoch 130/200\n",
            "94/94 - 90s - loss: 0.0354 - val_loss: 0.1337\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.12852\n",
            "Epoch 131/200\n",
            "94/94 - 90s - loss: 0.0404 - val_loss: 0.1412\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.12852\n",
            "Epoch 132/200\n",
            "94/94 - 90s - loss: 0.0453 - val_loss: 0.1461\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.12852\n",
            "Epoch 133/200\n",
            "94/94 - 90s - loss: 0.0451 - val_loss: 0.1372\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.12852\n",
            "Epoch 134/200\n",
            "94/94 - 90s - loss: 0.0397 - val_loss: 0.1353\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.12852\n",
            "Epoch 135/200\n",
            "94/94 - 90s - loss: 0.0349 - val_loss: 0.1331\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.12852\n",
            "Epoch 136/200\n",
            "94/94 - 90s - loss: 0.0308 - val_loss: 0.1299\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.12852\n",
            "Epoch 137/200\n",
            "94/94 - 90s - loss: 0.0350 - val_loss: 0.1343\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.12852\n",
            "Epoch 138/200\n",
            "94/94 - 90s - loss: 0.0339 - val_loss: 0.1354\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.12852\n",
            "Epoch 139/200\n",
            "94/94 - 90s - loss: 0.0322 - val_loss: 0.1276\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.12852 to 0.12760, saving model to model.h5\n",
            "Epoch 140/200\n",
            "94/94 - 91s - loss: 0.0284 - val_loss: 0.1260\n",
            "\n",
            "Epoch 00140: val_loss improved from 0.12760 to 0.12597, saving model to model.h5\n",
            "Epoch 141/200\n",
            "94/94 - 91s - loss: 0.0253 - val_loss: 0.1239\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.12597 to 0.12394, saving model to model.h5\n",
            "Epoch 142/200\n",
            "94/94 - 91s - loss: 0.0232 - val_loss: 0.1242\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.12394\n",
            "Epoch 143/200\n",
            "94/94 - 90s - loss: 0.0228 - val_loss: 0.1238\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.12394 to 0.12385, saving model to model.h5\n",
            "Epoch 144/200\n",
            "94/94 - 90s - loss: 0.0218 - val_loss: 0.1249\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.12385\n",
            "Epoch 145/200\n",
            "94/94 - 90s - loss: 0.0211 - val_loss: 0.1227\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.12385 to 0.12271, saving model to model.h5\n",
            "Epoch 146/200\n",
            "94/94 - 90s - loss: 0.0244 - val_loss: 0.1321\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.12271\n",
            "Epoch 147/200\n",
            "94/94 - 91s - loss: 0.0280 - val_loss: 0.1302\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.12271\n",
            "Epoch 148/200\n",
            "94/94 - 91s - loss: 0.0282 - val_loss: 0.1290\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.12271\n",
            "Epoch 149/200\n",
            "94/94 - 91s - loss: 0.0285 - val_loss: 0.1309\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.12271\n",
            "Epoch 150/200\n",
            "94/94 - 91s - loss: 0.0282 - val_loss: 0.1286\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.12271\n",
            "Epoch 151/200\n",
            "94/94 - 90s - loss: 0.0263 - val_loss: 0.1282\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.12271\n",
            "Epoch 152/200\n",
            "94/94 - 90s - loss: 0.0246 - val_loss: 0.1276\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.12271\n",
            "Epoch 153/200\n",
            "94/94 - 89s - loss: 0.0259 - val_loss: 0.1310\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.12271\n",
            "Epoch 154/200\n",
            "94/94 - 89s - loss: 0.0268 - val_loss: 0.1289\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.12271\n",
            "Epoch 155/200\n",
            "94/94 - 89s - loss: 0.0258 - val_loss: 0.1274\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.12271\n",
            "Epoch 156/200\n",
            "94/94 - 90s - loss: 0.0233 - val_loss: 0.1252\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.12271\n",
            "Epoch 157/200\n",
            "94/94 - 90s - loss: 0.0200 - val_loss: 0.1225\n",
            "\n",
            "Epoch 00157: val_loss improved from 0.12271 to 0.12254, saving model to model.h5\n",
            "Epoch 158/200\n",
            "94/94 - 90s - loss: 0.0185 - val_loss: 0.1227\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.12254\n",
            "Epoch 159/200\n",
            "94/94 - 91s - loss: 0.0185 - val_loss: 0.1242\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.12254\n",
            "Epoch 160/200\n",
            "94/94 - 90s - loss: 0.0212 - val_loss: 0.1277\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.12254\n",
            "Epoch 161/200\n",
            "94/94 - 90s - loss: 0.0225 - val_loss: 0.1262\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.12254\n",
            "Epoch 162/200\n",
            "94/94 - 91s - loss: 0.0223 - val_loss: 0.1251\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.12254\n",
            "Epoch 163/200\n",
            "94/94 - 90s - loss: 0.0216 - val_loss: 0.1282\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.12254\n",
            "Epoch 164/200\n",
            "94/94 - 90s - loss: 0.0230 - val_loss: 0.1319\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.12254\n",
            "Epoch 165/200\n",
            "94/94 - 91s - loss: 0.0269 - val_loss: 0.1322\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.12254\n",
            "Epoch 166/200\n",
            "94/94 - 92s - loss: 0.0281 - val_loss: 0.1282\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.12254\n",
            "Epoch 167/200\n",
            "94/94 - 92s - loss: 0.0255 - val_loss: 0.1306\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.12254\n",
            "Epoch 168/200\n",
            "94/94 - 92s - loss: 0.0238 - val_loss: 0.1263\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.12254\n",
            "Epoch 169/200\n",
            "94/94 - 91s - loss: 0.0208 - val_loss: 0.1247\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.12254\n",
            "Epoch 170/200\n",
            "94/94 - 90s - loss: 0.0185 - val_loss: 0.1237\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.12254\n",
            "Epoch 171/200\n",
            "94/94 - 90s - loss: 0.0265 - val_loss: 0.1288\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.12254\n",
            "Epoch 172/200\n",
            "94/94 - 90s - loss: 0.0257 - val_loss: 0.1312\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.12254\n",
            "Epoch 173/200\n",
            "94/94 - 91s - loss: 0.0249 - val_loss: 0.1266\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.12254\n",
            "Epoch 174/200\n",
            "94/94 - 91s - loss: 0.0187 - val_loss: 0.1230\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.12254\n",
            "Epoch 175/200\n",
            "94/94 - 92s - loss: 0.0153 - val_loss: 0.1200\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.12254 to 0.11996, saving model to model.h5\n",
            "Epoch 176/200\n",
            "94/94 - 92s - loss: 0.0136 - val_loss: 0.1209\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.11996\n",
            "Epoch 177/200\n",
            "94/94 - 91s - loss: 0.0132 - val_loss: 0.1196\n",
            "\n",
            "Epoch 00177: val_loss improved from 0.11996 to 0.11959, saving model to model.h5\n",
            "Epoch 178/200\n",
            "94/94 - 91s - loss: 0.0120 - val_loss: 0.1189\n",
            "\n",
            "Epoch 00178: val_loss improved from 0.11959 to 0.11889, saving model to model.h5\n",
            "Epoch 179/200\n",
            "94/94 - 90s - loss: 0.0114 - val_loss: 0.1181\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.11889 to 0.11810, saving model to model.h5\n",
            "Epoch 180/200\n",
            "94/94 - 91s - loss: 0.0111 - val_loss: 0.1187\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.11810\n",
            "Epoch 181/200\n",
            "94/94 - 90s - loss: 0.0116 - val_loss: 0.1203\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.11810\n",
            "Epoch 182/200\n",
            "94/94 - 91s - loss: 0.0120 - val_loss: 0.1204\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.11810\n",
            "Epoch 183/200\n",
            "94/94 - 91s - loss: 0.0122 - val_loss: 0.1197\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.11810\n",
            "Epoch 184/200\n",
            "94/94 - 92s - loss: 0.0128 - val_loss: 0.1209\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.11810\n",
            "Epoch 185/200\n",
            "94/94 - 92s - loss: 0.0124 - val_loss: 0.1208\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.11810\n",
            "Epoch 186/200\n",
            "94/94 - 91s - loss: 0.0138 - val_loss: 0.1235\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.11810\n",
            "Epoch 187/200\n",
            "94/94 - 90s - loss: 0.0173 - val_loss: 0.1277\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.11810\n",
            "Epoch 188/200\n",
            "94/94 - 90s - loss: 0.0251 - val_loss: 0.1394\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.11810\n",
            "Epoch 189/200\n",
            "94/94 - 90s - loss: 0.0365 - val_loss: 0.1442\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.11810\n",
            "Epoch 190/200\n",
            "94/94 - 90s - loss: 0.0428 - val_loss: 0.1414\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.11810\n",
            "Epoch 191/200\n",
            "94/94 - 90s - loss: 0.0337 - val_loss: 0.1327\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.11810\n",
            "Epoch 192/200\n",
            "94/94 - 91s - loss: 0.0225 - val_loss: 0.1243\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.11810\n",
            "Epoch 193/200\n",
            "94/94 - 90s - loss: 0.0157 - val_loss: 0.1228\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.11810\n",
            "Epoch 194/200\n",
            "94/94 - 90s - loss: 0.0129 - val_loss: 0.1199\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.11810\n",
            "Epoch 195/200\n",
            "94/94 - 91s - loss: 0.0122 - val_loss: 0.1188\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.11810\n",
            "Epoch 196/200\n",
            "94/94 - 90s - loss: 0.0114 - val_loss: 0.1192\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.11810\n",
            "Epoch 197/200\n",
            "94/94 - 91s - loss: 0.0107 - val_loss: 0.1185\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.11810\n",
            "Epoch 198/200\n",
            "94/94 - 90s - loss: 0.0100 - val_loss: 0.1196\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.11810\n",
            "Epoch 199/200\n",
            "94/94 - 90s - loss: 0.0099 - val_loss: 0.1185\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.11810\n",
            "Epoch 200/200\n",
            "94/94 - 90s - loss: 0.0091 - val_loss: 0.1183\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.11810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f77a774b410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRQ8wYbaAt-T",
        "outputId": "cf031a6d-c7a3-4961-d251-f3ca6d097ef9"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "print('Icelandic Vocabulary Size: %d' % ger_vocab_size)\n",
        "print('Icelandic  Max Length: %d' % (ger_length))\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_output(trainY, eng_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_output(testY, eng_vocab_size)\n",
        "\n",
        "# define model\n",
        "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# fit model\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3624\n",
            "English Max Length: 38\n",
            "Icelandic Vocabulary Size: 6233\n",
            "Icelandic  Max Length: 35\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 35, 256)           1595648   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 38, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 38, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 38, 3624)          931368    \n",
            "=================================================================\n",
            "Total params: 3,577,640\n",
            "Trainable params: 3,577,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "94/94 - 120s - loss: 2.1059 - val_loss: 1.2378\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.23782, saving model to model.h5\n",
            "Epoch 2/100\n",
            "94/94 - 111s - loss: 1.2236 - val_loss: 1.2273\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.23782 to 1.22726, saving model to model.h5\n",
            "Epoch 3/100\n",
            "94/94 - 111s - loss: 1.1832 - val_loss: 1.0818\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.22726 to 1.08176, saving model to model.h5\n",
            "Epoch 4/100\n",
            "94/94 - 111s - loss: 1.0558 - val_loss: 1.0403\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.08176 to 1.04029, saving model to model.h5\n",
            "Epoch 5/100\n",
            "94/94 - 110s - loss: 1.0349 - val_loss: 1.0295\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.04029 to 1.02952, saving model to model.h5\n",
            "Epoch 6/100\n",
            "94/94 - 109s - loss: 1.0213 - val_loss: 1.0278\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.02952 to 1.02778, saving model to model.h5\n",
            "Epoch 7/100\n",
            "94/94 - 110s - loss: 1.0102 - val_loss: 1.0020\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.02778 to 1.00204, saving model to model.h5\n",
            "Epoch 8/100\n",
            "94/94 - 109s - loss: 1.0002 - val_loss: 0.9927\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.00204 to 0.99273, saving model to model.h5\n",
            "Epoch 9/100\n",
            "94/94 - 109s - loss: 0.9910 - val_loss: 0.9838\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.99273 to 0.98383, saving model to model.h5\n",
            "Epoch 10/100\n",
            "94/94 - 109s - loss: 0.9827 - val_loss: 0.9778\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.98383 to 0.97777, saving model to model.h5\n",
            "Epoch 11/100\n",
            "94/94 - 109s - loss: 0.9749 - val_loss: 0.9752\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.97777 to 0.97518, saving model to model.h5\n",
            "Epoch 12/100\n",
            "94/94 - 109s - loss: 0.9673 - val_loss: 0.9638\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.97518 to 0.96381, saving model to model.h5\n",
            "Epoch 13/100\n",
            "94/94 - 109s - loss: 0.9598 - val_loss: 0.9571\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.96381 to 0.95714, saving model to model.h5\n",
            "Epoch 14/100\n",
            "94/94 - 109s - loss: 0.9526 - val_loss: 0.9511\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.95714 to 0.95115, saving model to model.h5\n",
            "Epoch 15/100\n",
            "94/94 - 109s - loss: 0.9479 - val_loss: 0.9504\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.95115 to 0.95040, saving model to model.h5\n",
            "Epoch 16/100\n",
            "94/94 - 109s - loss: 0.9403 - val_loss: 0.9405\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.95040 to 0.94053, saving model to model.h5\n",
            "Epoch 17/100\n",
            "94/94 - 109s - loss: 0.9331 - val_loss: 0.9338\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.94053 to 0.93377, saving model to model.h5\n",
            "Epoch 18/100\n",
            "94/94 - 110s - loss: 0.9263 - val_loss: 0.9289\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.93377 to 0.92888, saving model to model.h5\n",
            "Epoch 19/100\n",
            "94/94 - 111s - loss: 0.9198 - val_loss: 0.9191\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.92888 to 0.91908, saving model to model.h5\n",
            "Epoch 20/100\n",
            "94/94 - 111s - loss: 0.9091 - val_loss: 0.9112\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.91908 to 0.91122, saving model to model.h5\n",
            "Epoch 21/100\n",
            "94/94 - 110s - loss: 0.8980 - val_loss: 0.8998\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.91122 to 0.89976, saving model to model.h5\n",
            "Epoch 22/100\n",
            "94/94 - 110s - loss: 0.8879 - val_loss: 0.8895\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.89976 to 0.88950, saving model to model.h5\n",
            "Epoch 23/100\n",
            "94/94 - 111s - loss: 0.8745 - val_loss: 0.8833\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.88950 to 0.88332, saving model to model.h5\n",
            "Epoch 24/100\n",
            "94/94 - 109s - loss: 0.8647 - val_loss: 0.8644\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.88332 to 0.86437, saving model to model.h5\n",
            "Epoch 25/100\n",
            "94/94 - 109s - loss: 0.8510 - val_loss: 0.8532\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.86437 to 0.85316, saving model to model.h5\n",
            "Epoch 26/100\n",
            "94/94 - 111s - loss: 0.8366 - val_loss: 0.8421\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.85316 to 0.84205, saving model to model.h5\n",
            "Epoch 27/100\n",
            "94/94 - 111s - loss: 0.8231 - val_loss: 0.8276\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.84205 to 0.82760, saving model to model.h5\n",
            "Epoch 28/100\n",
            "94/94 - 111s - loss: 0.8106 - val_loss: 0.8172\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.82760 to 0.81718, saving model to model.h5\n",
            "Epoch 29/100\n",
            "94/94 - 111s - loss: 0.7996 - val_loss: 0.8046\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.81718 to 0.80459, saving model to model.h5\n",
            "Epoch 30/100\n",
            "94/94 - 111s - loss: 0.7862 - val_loss: 0.7923\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.80459 to 0.79231, saving model to model.h5\n",
            "Epoch 31/100\n",
            "94/94 - 110s - loss: 0.7724 - val_loss: 0.7782\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.79231 to 0.77815, saving model to model.h5\n",
            "Epoch 32/100\n",
            "94/94 - 110s - loss: 0.7530 - val_loss: 0.7557\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.77815 to 0.75568, saving model to model.h5\n",
            "Epoch 33/100\n",
            "94/94 - 109s - loss: 0.7332 - val_loss: 0.7395\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.75568 to 0.73955, saving model to model.h5\n",
            "Epoch 34/100\n",
            "94/94 - 109s - loss: 0.7142 - val_loss: 0.7225\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.73955 to 0.72250, saving model to model.h5\n",
            "Epoch 35/100\n",
            "94/94 - 109s - loss: 0.6961 - val_loss: 0.7046\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.72250 to 0.70463, saving model to model.h5\n",
            "Epoch 36/100\n",
            "94/94 - 109s - loss: 0.6772 - val_loss: 0.6845\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.70463 to 0.68452, saving model to model.h5\n",
            "Epoch 37/100\n",
            "94/94 - 109s - loss: 0.6577 - val_loss: 0.6685\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.68452 to 0.66852, saving model to model.h5\n",
            "Epoch 38/100\n",
            "94/94 - 109s - loss: 0.6435 - val_loss: 0.6521\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.66852 to 0.65213, saving model to model.h5\n",
            "Epoch 39/100\n",
            "94/94 - 109s - loss: 0.6263 - val_loss: 0.6388\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.65213 to 0.63876, saving model to model.h5\n",
            "Epoch 40/100\n",
            "94/94 - 109s - loss: 0.6074 - val_loss: 0.6238\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.63876 to 0.62381, saving model to model.h5\n",
            "Epoch 41/100\n",
            "94/94 - 110s - loss: 0.5908 - val_loss: 0.6010\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.62381 to 0.60099, saving model to model.h5\n",
            "Epoch 42/100\n",
            "94/94 - 109s - loss: 0.5725 - val_loss: 0.5871\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.60099 to 0.58714, saving model to model.h5\n",
            "Epoch 43/100\n",
            "94/94 - 109s - loss: 0.5529 - val_loss: 0.5710\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.58714 to 0.57101, saving model to model.h5\n",
            "Epoch 44/100\n",
            "94/94 - 109s - loss: 0.5346 - val_loss: 0.5543\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.57101 to 0.55425, saving model to model.h5\n",
            "Epoch 45/100\n",
            "94/94 - 109s - loss: 0.5201 - val_loss: 0.5405\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.55425 to 0.54047, saving model to model.h5\n",
            "Epoch 46/100\n",
            "94/94 - 109s - loss: 0.5038 - val_loss: 0.5312\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.54047 to 0.53115, saving model to model.h5\n",
            "Epoch 47/100\n",
            "94/94 - 109s - loss: 0.4977 - val_loss: 0.5245\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.53115 to 0.52454, saving model to model.h5\n",
            "Epoch 48/100\n",
            "94/94 - 109s - loss: 0.4789 - val_loss: 0.4985\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.52454 to 0.49849, saving model to model.h5\n",
            "Epoch 49/100\n",
            "94/94 - 109s - loss: 0.4586 - val_loss: 0.4889\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.49849 to 0.48886, saving model to model.h5\n",
            "Epoch 50/100\n",
            "94/94 - 109s - loss: 0.4446 - val_loss: 0.4736\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.48886 to 0.47356, saving model to model.h5\n",
            "Epoch 51/100\n",
            "94/94 - 110s - loss: 0.4304 - val_loss: 0.4630\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.47356 to 0.46295, saving model to model.h5\n",
            "Epoch 52/100\n",
            "94/94 - 111s - loss: 0.4140 - val_loss: 0.4445\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.46295 to 0.44447, saving model to model.h5\n",
            "Epoch 53/100\n",
            "94/94 - 111s - loss: 0.3987 - val_loss: 0.4394\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.44447 to 0.43945, saving model to model.h5\n",
            "Epoch 54/100\n",
            "94/94 - 109s - loss: 0.3869 - val_loss: 0.4225\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.43945 to 0.42247, saving model to model.h5\n",
            "Epoch 55/100\n",
            "94/94 - 110s - loss: 0.3748 - val_loss: 0.4198\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.42247 to 0.41982, saving model to model.h5\n",
            "Epoch 56/100\n",
            "94/94 - 111s - loss: 0.3655 - val_loss: 0.4088\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.41982 to 0.40881, saving model to model.h5\n",
            "Epoch 57/100\n",
            "94/94 - 110s - loss: 0.3543 - val_loss: 0.3922\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.40881 to 0.39216, saving model to model.h5\n",
            "Epoch 58/100\n",
            "94/94 - 111s - loss: 0.3391 - val_loss: 0.3801\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.39216 to 0.38010, saving model to model.h5\n",
            "Epoch 59/100\n",
            "94/94 - 113s - loss: 0.3254 - val_loss: 0.3710\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.38010 to 0.37096, saving model to model.h5\n",
            "Epoch 60/100\n",
            "94/94 - 114s - loss: 0.3123 - val_loss: 0.3611\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.37096 to 0.36109, saving model to model.h5\n",
            "Epoch 61/100\n",
            "94/94 - 110s - loss: 0.3015 - val_loss: 0.3517\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.36109 to 0.35169, saving model to model.h5\n",
            "Epoch 62/100\n",
            "94/94 - 111s - loss: 0.2953 - val_loss: 0.3467\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.35169 to 0.34670, saving model to model.h5\n",
            "Epoch 63/100\n",
            "94/94 - 112s - loss: 0.2881 - val_loss: 0.3365\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.34670 to 0.33648, saving model to model.h5\n",
            "Epoch 64/100\n",
            "94/94 - 110s - loss: 0.2749 - val_loss: 0.3249\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.33648 to 0.32487, saving model to model.h5\n",
            "Epoch 65/100\n",
            "94/94 - 110s - loss: 0.2659 - val_loss: 0.3188\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.32487 to 0.31884, saving model to model.h5\n",
            "Epoch 66/100\n",
            "94/94 - 109s - loss: 0.2557 - val_loss: 0.3090\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.31884 to 0.30898, saving model to model.h5\n",
            "Epoch 67/100\n",
            "94/94 - 109s - loss: 0.2449 - val_loss: 0.3047\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.30898 to 0.30472, saving model to model.h5\n",
            "Epoch 68/100\n",
            "94/94 - 109s - loss: 0.2379 - val_loss: 0.2946\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.30472 to 0.29460, saving model to model.h5\n",
            "Epoch 69/100\n",
            "94/94 - 109s - loss: 0.2284 - val_loss: 0.2894\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.29460 to 0.28945, saving model to model.h5\n",
            "Epoch 70/100\n",
            "94/94 - 109s - loss: 0.2204 - val_loss: 0.2795\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.28945 to 0.27951, saving model to model.h5\n",
            "Epoch 71/100\n",
            "94/94 - 110s - loss: 0.2102 - val_loss: 0.2723\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.27951 to 0.27234, saving model to model.h5\n",
            "Epoch 72/100\n",
            "94/94 - 109s - loss: 0.2036 - val_loss: 0.2729\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.27234\n",
            "Epoch 73/100\n",
            "94/94 - 109s - loss: 0.1970 - val_loss: 0.2640\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.27234 to 0.26398, saving model to model.h5\n",
            "Epoch 74/100\n",
            "94/94 - 109s - loss: 0.1919 - val_loss: 0.2602\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.26398 to 0.26016, saving model to model.h5\n",
            "Epoch 75/100\n",
            "94/94 - 110s - loss: 0.1845 - val_loss: 0.2492\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.26016 to 0.24923, saving model to model.h5\n",
            "Epoch 76/100\n",
            "94/94 - 110s - loss: 0.1758 - val_loss: 0.2451\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.24923 to 0.24510, saving model to model.h5\n",
            "Epoch 77/100\n",
            "94/94 - 110s - loss: 0.1710 - val_loss: 0.2428\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.24510 to 0.24282, saving model to model.h5\n",
            "Epoch 78/100\n",
            "94/94 - 109s - loss: 0.1644 - val_loss: 0.2371\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.24282 to 0.23712, saving model to model.h5\n",
            "Epoch 79/100\n",
            "94/94 - 109s - loss: 0.1612 - val_loss: 0.2384\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.23712\n",
            "Epoch 80/100\n",
            "94/94 - 109s - loss: 0.1563 - val_loss: 0.2259\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.23712 to 0.22593, saving model to model.h5\n",
            "Epoch 81/100\n",
            "94/94 - 109s - loss: 0.1475 - val_loss: 0.2179\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.22593 to 0.21787, saving model to model.h5\n",
            "Epoch 82/100\n",
            "94/94 - 109s - loss: 0.1386 - val_loss: 0.2191\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.21787\n",
            "Epoch 83/100\n",
            "94/94 - 109s - loss: 0.1341 - val_loss: 0.2156\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.21787 to 0.21556, saving model to model.h5\n",
            "Epoch 84/100\n",
            "94/94 - 111s - loss: 0.1298 - val_loss: 0.2087\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.21556 to 0.20873, saving model to model.h5\n",
            "Epoch 85/100\n",
            "94/94 - 111s - loss: 0.1245 - val_loss: 0.2026\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.20873 to 0.20260, saving model to model.h5\n",
            "Epoch 86/100\n",
            "94/94 - 112s - loss: 0.1183 - val_loss: 0.1986\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.20260 to 0.19855, saving model to model.h5\n",
            "Epoch 87/100\n",
            "94/94 - 110s - loss: 0.1153 - val_loss: 0.1936\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.19855 to 0.19359, saving model to model.h5\n",
            "Epoch 88/100\n",
            "94/94 - 110s - loss: 0.1117 - val_loss: 0.1946\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.19359\n",
            "Epoch 89/100\n",
            "94/94 - 110s - loss: 0.1087 - val_loss: 0.1886\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.19359 to 0.18858, saving model to model.h5\n",
            "Epoch 90/100\n",
            "94/94 - 109s - loss: 0.1036 - val_loss: 0.1870\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.18858 to 0.18697, saving model to model.h5\n",
            "Epoch 91/100\n",
            "94/94 - 109s - loss: 0.1003 - val_loss: 0.1828\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.18697 to 0.18277, saving model to model.h5\n",
            "Epoch 92/100\n",
            "94/94 - 111s - loss: 0.0959 - val_loss: 0.1783\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.18277 to 0.17827, saving model to model.h5\n",
            "Epoch 93/100\n",
            "94/94 - 111s - loss: 0.0926 - val_loss: 0.1782\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.17827 to 0.17815, saving model to model.h5\n",
            "Epoch 94/100\n",
            "94/94 - 110s - loss: 0.0892 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.17815 to 0.17387, saving model to model.h5\n",
            "Epoch 95/100\n",
            "94/94 - 111s - loss: 0.0859 - val_loss: 0.1704\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.17387 to 0.17042, saving model to model.h5\n",
            "Epoch 96/100\n",
            "94/94 - 110s - loss: 0.0818 - val_loss: 0.1694\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.17042 to 0.16936, saving model to model.h5\n",
            "Epoch 97/100\n",
            "94/94 - 110s - loss: 0.0792 - val_loss: 0.1664\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.16936 to 0.16638, saving model to model.h5\n",
            "Epoch 98/100\n",
            "94/94 - 111s - loss: 0.0761 - val_loss: 0.1647\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.16638 to 0.16469, saving model to model.h5\n",
            "Epoch 99/100\n",
            "94/94 - 110s - loss: 0.0758 - val_loss: 0.1697\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.16469\n",
            "Epoch 100/100\n",
            "94/94 - 109s - loss: 0.0856 - val_loss: 0.1772\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.16469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f05b996d650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kwz4aqZVfpd",
        "outputId": "43fc3e0d-5d7c-4e40-ae40-5de7901382f4"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "# define NMT model\n",
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(LSTM(n_units))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "\treturn model\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "print('Icelandic Vocabulary Size: %d' % ger_vocab_size)\n",
        "print('Icelandic  Max Length: %d' % (ger_length))\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_output(trainY, eng_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_output(testY, eng_vocab_size)\n",
        "\n",
        "# define model\n",
        "model = define_model(ger_vocab_size, eng_vocab_size, ger_length, eng_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# summarize defined model\n",
        "print(model.summary())\n",
        "plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# fit model\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3624\n",
            "English Max Length: 38\n",
            "Icelandic Vocabulary Size: 6233\n",
            "Icelandic  Max Length: 35\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 35, 256)           1595648   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 38, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 38, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 38, 3624)          931368    \n",
            "=================================================================\n",
            "Total params: 3,577,640\n",
            "Trainable params: 3,577,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "94/94 - 130s - loss: 2.0948 - val_loss: 1.2164\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.21645, saving model to model.h5\n",
            "Epoch 2/200\n",
            "94/94 - 123s - loss: 1.2243 - val_loss: 1.2200\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.21645\n",
            "Epoch 3/200\n",
            "94/94 - 124s - loss: 1.1896 - val_loss: 1.1704\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.21645 to 1.17045, saving model to model.h5\n",
            "Epoch 4/200\n",
            "94/94 - 126s - loss: 1.1002 - val_loss: 1.0421\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.17045 to 1.04214, saving model to model.h5\n",
            "Epoch 5/200\n",
            "94/94 - 123s - loss: 1.0376 - val_loss: 1.0252\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.04214 to 1.02524, saving model to model.h5\n",
            "Epoch 6/200\n",
            "94/94 - 122s - loss: 1.0234 - val_loss: 1.0126\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.02524 to 1.01256, saving model to model.h5\n",
            "Epoch 7/200\n",
            "94/94 - 122s - loss: 1.0101 - val_loss: 1.0030\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.01256 to 1.00298, saving model to model.h5\n",
            "Epoch 8/200\n",
            "94/94 - 122s - loss: 0.9988 - val_loss: 0.9923\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.00298 to 0.99230, saving model to model.h5\n",
            "Epoch 9/200\n",
            "94/94 - 123s - loss: 0.9896 - val_loss: 0.9845\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.99230 to 0.98453, saving model to model.h5\n",
            "Epoch 10/200\n",
            "94/94 - 122s - loss: 0.9834 - val_loss: 0.9803\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.98453 to 0.98032, saving model to model.h5\n",
            "Epoch 11/200\n",
            "94/94 - 122s - loss: 0.9744 - val_loss: 0.9700\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.98032 to 0.96999, saving model to model.h5\n",
            "Epoch 12/200\n",
            "94/94 - 122s - loss: 0.9685 - val_loss: 0.9666\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.96999 to 0.96659, saving model to model.h5\n",
            "Epoch 13/200\n",
            "94/94 - 122s - loss: 0.9606 - val_loss: 0.9600\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.96659 to 0.96004, saving model to model.h5\n",
            "Epoch 14/200\n",
            "94/94 - 122s - loss: 0.9559 - val_loss: 0.9611\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.96004\n",
            "Epoch 15/200\n",
            "94/94 - 123s - loss: 0.9520 - val_loss: 0.9572\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.96004 to 0.95721, saving model to model.h5\n",
            "Epoch 16/200\n",
            "94/94 - 125s - loss: 0.9456 - val_loss: 0.9510\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.95721 to 0.95105, saving model to model.h5\n",
            "Epoch 17/200\n",
            "94/94 - 124s - loss: 0.9395 - val_loss: 0.9443\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.95105 to 0.94427, saving model to model.h5\n",
            "Epoch 18/200\n",
            "94/94 - 123s - loss: 0.9338 - val_loss: 0.9338\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.94427 to 0.93381, saving model to model.h5\n",
            "Epoch 19/200\n",
            "94/94 - 123s - loss: 0.9251 - val_loss: 0.9336\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.93381 to 0.93364, saving model to model.h5\n",
            "Epoch 20/200\n",
            "94/94 - 123s - loss: 0.9197 - val_loss: 0.9194\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.93364 to 0.91941, saving model to model.h5\n",
            "Epoch 21/200\n",
            "94/94 - 122s - loss: 0.9087 - val_loss: 0.9140\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.91941 to 0.91396, saving model to model.h5\n",
            "Epoch 22/200\n",
            "94/94 - 122s - loss: 0.9013 - val_loss: 0.9040\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.91396 to 0.90396, saving model to model.h5\n",
            "Epoch 23/200\n",
            "94/94 - 122s - loss: 0.8892 - val_loss: 0.8932\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.90396 to 0.89324, saving model to model.h5\n",
            "Epoch 24/200\n",
            "94/94 - 122s - loss: 0.8816 - val_loss: 0.8873\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.89324 to 0.88727, saving model to model.h5\n",
            "Epoch 25/200\n",
            "94/94 - 122s - loss: 0.8685 - val_loss: 0.8730\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.88727 to 0.87298, saving model to model.h5\n",
            "Epoch 26/200\n",
            "94/94 - 123s - loss: 0.8556 - val_loss: 0.8599\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.87298 to 0.85993, saving model to model.h5\n",
            "Epoch 27/200\n",
            "94/94 - 123s - loss: 0.8425 - val_loss: 0.8494\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.85993 to 0.84945, saving model to model.h5\n",
            "Epoch 28/200\n",
            "94/94 - 122s - loss: 0.8281 - val_loss: 0.8318\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.84945 to 0.83181, saving model to model.h5\n",
            "Epoch 29/200\n",
            "94/94 - 122s - loss: 0.8183 - val_loss: 0.8162\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.83181 to 0.81622, saving model to model.h5\n",
            "Epoch 30/200\n",
            "94/94 - 123s - loss: 0.7961 - val_loss: 0.7989\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.81622 to 0.79894, saving model to model.h5\n",
            "Epoch 31/200\n",
            "94/94 - 123s - loss: 0.7776 - val_loss: 0.7825\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.79894 to 0.78245, saving model to model.h5\n",
            "Epoch 32/200\n",
            "94/94 - 123s - loss: 0.7609 - val_loss: 0.7666\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.78245 to 0.76659, saving model to model.h5\n",
            "Epoch 33/200\n",
            "94/94 - 123s - loss: 0.7457 - val_loss: 0.7542\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.76659 to 0.75416, saving model to model.h5\n",
            "Epoch 34/200\n",
            "94/94 - 122s - loss: 0.7313 - val_loss: 0.7413\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.75416 to 0.74131, saving model to model.h5\n",
            "Epoch 35/200\n",
            "94/94 - 122s - loss: 0.7161 - val_loss: 0.7242\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.74131 to 0.72424, saving model to model.h5\n",
            "Epoch 36/200\n",
            "94/94 - 128s - loss: 0.6987 - val_loss: 0.7128\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.72424 to 0.71278, saving model to model.h5\n",
            "Epoch 37/200\n",
            "94/94 - 132s - loss: 0.6824 - val_loss: 0.6901\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.71278 to 0.69014, saving model to model.h5\n",
            "Epoch 38/200\n",
            "94/94 - 132s - loss: 0.6644 - val_loss: 0.6760\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.69014 to 0.67597, saving model to model.h5\n",
            "Epoch 39/200\n",
            "94/94 - 132s - loss: 0.6462 - val_loss: 0.6593\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.67597 to 0.65926, saving model to model.h5\n",
            "Epoch 40/200\n",
            "94/94 - 131s - loss: 0.6268 - val_loss: 0.6404\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.65926 to 0.64036, saving model to model.h5\n",
            "Epoch 41/200\n",
            "94/94 - 132s - loss: 0.6085 - val_loss: 0.6226\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.64036 to 0.62264, saving model to model.h5\n",
            "Epoch 42/200\n",
            "94/94 - 132s - loss: 0.5919 - val_loss: 0.6142\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.62264 to 0.61416, saving model to model.h5\n",
            "Epoch 43/200\n",
            "94/94 - 132s - loss: 0.5771 - val_loss: 0.5940\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.61416 to 0.59399, saving model to model.h5\n",
            "Epoch 44/200\n",
            "94/94 - 132s - loss: 0.5602 - val_loss: 0.5794\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.59399 to 0.57937, saving model to model.h5\n",
            "Epoch 45/200\n",
            "94/94 - 131s - loss: 0.5435 - val_loss: 0.5666\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.57937 to 0.56660, saving model to model.h5\n",
            "Epoch 46/200\n",
            "94/94 - 131s - loss: 0.5280 - val_loss: 0.5499\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.56660 to 0.54988, saving model to model.h5\n",
            "Epoch 47/200\n",
            "94/94 - 132s - loss: 0.5113 - val_loss: 0.5361\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.54988 to 0.53614, saving model to model.h5\n",
            "Epoch 48/200\n",
            "94/94 - 133s - loss: 0.4974 - val_loss: 0.5232\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.53614 to 0.52322, saving model to model.h5\n",
            "Epoch 49/200\n",
            "94/94 - 132s - loss: 0.4824 - val_loss: 0.5080\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.52322 to 0.50798, saving model to model.h5\n",
            "Epoch 50/200\n",
            "94/94 - 131s - loss: 0.4684 - val_loss: 0.4951\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.50798 to 0.49508, saving model to model.h5\n",
            "Epoch 51/200\n",
            "94/94 - 133s - loss: 0.4520 - val_loss: 0.4826\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.49508 to 0.48260, saving model to model.h5\n",
            "Epoch 52/200\n",
            "94/94 - 132s - loss: 0.4378 - val_loss: 0.4704\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.48260 to 0.47039, saving model to model.h5\n",
            "Epoch 53/200\n",
            "94/94 - 130s - loss: 0.4244 - val_loss: 0.4616\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.47039 to 0.46163, saving model to model.h5\n",
            "Epoch 54/200\n",
            "94/94 - 132s - loss: 0.4119 - val_loss: 0.4510\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.46163 to 0.45098, saving model to model.h5\n",
            "Epoch 55/200\n",
            "94/94 - 131s - loss: 0.3978 - val_loss: 0.4341\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.45098 to 0.43415, saving model to model.h5\n",
            "Epoch 56/200\n",
            "94/94 - 131s - loss: 0.3842 - val_loss: 0.4311\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.43415 to 0.43109, saving model to model.h5\n",
            "Epoch 57/200\n",
            "94/94 - 132s - loss: 0.3723 - val_loss: 0.4185\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.43109 to 0.41855, saving model to model.h5\n",
            "Epoch 58/200\n",
            "94/94 - 132s - loss: 0.3595 - val_loss: 0.4057\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.41855 to 0.40570, saving model to model.h5\n",
            "Epoch 59/200\n",
            "94/94 - 133s - loss: 0.3486 - val_loss: 0.3932\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.40570 to 0.39323, saving model to model.h5\n",
            "Epoch 60/200\n",
            "94/94 - 133s - loss: 0.3369 - val_loss: 0.3846\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.39323 to 0.38456, saving model to model.h5\n",
            "Epoch 61/200\n",
            "94/94 - 134s - loss: 0.3249 - val_loss: 0.3718\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.38456 to 0.37183, saving model to model.h5\n",
            "Epoch 62/200\n",
            "94/94 - 132s - loss: 0.3133 - val_loss: 0.3653\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.37183 to 0.36527, saving model to model.h5\n",
            "Epoch 63/200\n",
            "94/94 - 132s - loss: 0.3030 - val_loss: 0.3572\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.36527 to 0.35722, saving model to model.h5\n",
            "Epoch 64/200\n",
            "94/94 - 124s - loss: 0.2935 - val_loss: 0.3471\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.35722 to 0.34707, saving model to model.h5\n",
            "Epoch 65/200\n",
            "94/94 - 123s - loss: 0.2845 - val_loss: 0.3375\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.34707 to 0.33747, saving model to model.h5\n",
            "Epoch 66/200\n",
            "94/94 - 124s - loss: 0.2750 - val_loss: 0.3330\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.33747 to 0.33296, saving model to model.h5\n",
            "Epoch 67/200\n",
            "94/94 - 124s - loss: 0.2652 - val_loss: 0.3217\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.33296 to 0.32169, saving model to model.h5\n",
            "Epoch 68/200\n",
            "94/94 - 124s - loss: 0.2564 - val_loss: 0.3175\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.32169 to 0.31750, saving model to model.h5\n",
            "Epoch 69/200\n",
            "94/94 - 124s - loss: 0.2457 - val_loss: 0.3054\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.31750 to 0.30540, saving model to model.h5\n",
            "Epoch 70/200\n",
            "94/94 - 123s - loss: 0.2362 - val_loss: 0.3046\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.30540 to 0.30456, saving model to model.h5\n",
            "Epoch 71/200\n",
            "94/94 - 123s - loss: 0.2289 - val_loss: 0.2946\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.30456 to 0.29461, saving model to model.h5\n",
            "Epoch 72/200\n",
            "94/94 - 124s - loss: 0.2208 - val_loss: 0.2835\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.29461 to 0.28351, saving model to model.h5\n",
            "Epoch 73/200\n",
            "94/94 - 124s - loss: 0.2124 - val_loss: 0.2819\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.28351 to 0.28188, saving model to model.h5\n",
            "Epoch 74/200\n",
            "94/94 - 124s - loss: 0.2056 - val_loss: 0.2714\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.28188 to 0.27142, saving model to model.h5\n",
            "Epoch 75/200\n",
            "94/94 - 123s - loss: 0.1972 - val_loss: 0.2655\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.27142 to 0.26548, saving model to model.h5\n",
            "Epoch 76/200\n",
            "94/94 - 123s - loss: 0.1902 - val_loss: 0.2614\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.26548 to 0.26143, saving model to model.h5\n",
            "Epoch 77/200\n",
            "94/94 - 124s - loss: 0.1839 - val_loss: 0.2573\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.26143 to 0.25727, saving model to model.h5\n",
            "Epoch 78/200\n",
            "94/94 - 123s - loss: 0.1790 - val_loss: 0.2507\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.25727 to 0.25068, saving model to model.h5\n",
            "Epoch 79/200\n",
            "94/94 - 124s - loss: 0.1761 - val_loss: 0.2513\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.25068\n",
            "Epoch 80/200\n",
            "94/94 - 125s - loss: 0.1691 - val_loss: 0.2419\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.25068 to 0.24186, saving model to model.h5\n",
            "Epoch 81/200\n",
            "94/94 - 123s - loss: 0.1605 - val_loss: 0.2425\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.24186\n",
            "Epoch 82/200\n",
            "94/94 - 123s - loss: 0.1544 - val_loss: 0.2315\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.24186 to 0.23151, saving model to model.h5\n",
            "Epoch 83/200\n",
            "94/94 - 123s - loss: 0.1484 - val_loss: 0.2266\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.23151 to 0.22656, saving model to model.h5\n",
            "Epoch 84/200\n",
            "94/94 - 124s - loss: 0.1434 - val_loss: 0.2241\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.22656 to 0.22406, saving model to model.h5\n",
            "Epoch 85/200\n",
            "94/94 - 123s - loss: 0.1391 - val_loss: 0.2287\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.22406\n",
            "Epoch 86/200\n",
            "94/94 - 123s - loss: 0.1361 - val_loss: 0.2174\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.22406 to 0.21741, saving model to model.h5\n",
            "Epoch 87/200\n",
            "94/94 - 123s - loss: 0.1318 - val_loss: 0.2159\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.21741 to 0.21590, saving model to model.h5\n",
            "Epoch 88/200\n",
            "94/94 - 123s - loss: 0.1272 - val_loss: 0.2075\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.21590 to 0.20748, saving model to model.h5\n",
            "Epoch 89/200\n",
            "94/94 - 123s - loss: 0.1201 - val_loss: 0.2042\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.20748 to 0.20423, saving model to model.h5\n",
            "Epoch 90/200\n",
            "94/94 - 124s - loss: 0.1151 - val_loss: 0.1988\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.20423 to 0.19882, saving model to model.h5\n",
            "Epoch 91/200\n",
            "94/94 - 124s - loss: 0.1104 - val_loss: 0.1966\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.19882 to 0.19662, saving model to model.h5\n",
            "Epoch 92/200\n",
            "94/94 - 123s - loss: 0.1070 - val_loss: 0.1953\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.19662 to 0.19527, saving model to model.h5\n",
            "Epoch 93/200\n",
            "94/94 - 124s - loss: 0.1042 - val_loss: 0.1930\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.19527 to 0.19303, saving model to model.h5\n",
            "Epoch 94/200\n",
            "94/94 - 124s - loss: 0.1014 - val_loss: 0.1955\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.19303\n",
            "Epoch 95/200\n",
            "94/94 - 123s - loss: 0.1008 - val_loss: 0.1893\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.19303 to 0.18931, saving model to model.h5\n",
            "Epoch 96/200\n",
            "94/94 - 123s - loss: 0.0959 - val_loss: 0.1836\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.18931 to 0.18361, saving model to model.h5\n",
            "Epoch 97/200\n",
            "94/94 - 123s - loss: 0.0927 - val_loss: 0.1827\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.18361 to 0.18274, saving model to model.h5\n",
            "Epoch 98/200\n",
            "94/94 - 123s - loss: 0.0888 - val_loss: 0.1877\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.18274\n",
            "Epoch 99/200\n",
            "94/94 - 123s - loss: 0.0885 - val_loss: 0.1795\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.18274 to 0.17946, saving model to model.h5\n",
            "Epoch 100/200\n",
            "94/94 - 124s - loss: 0.0835 - val_loss: 0.1755\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.17946 to 0.17553, saving model to model.h5\n",
            "Epoch 101/200\n",
            "94/94 - 125s - loss: 0.0795 - val_loss: 0.1718\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.17553 to 0.17183, saving model to model.h5\n",
            "Epoch 102/200\n",
            "94/94 - 124s - loss: 0.0757 - val_loss: 0.1723\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.17183\n",
            "Epoch 103/200\n",
            "94/94 - 124s - loss: 0.0727 - val_loss: 0.1671\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.17183 to 0.16711, saving model to model.h5\n",
            "Epoch 104/200\n",
            "94/94 - 123s - loss: 0.0714 - val_loss: 0.1687\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.16711\n",
            "Epoch 105/200\n",
            "94/94 - 122s - loss: 0.0709 - val_loss: 0.1656\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.16711 to 0.16556, saving model to model.h5\n",
            "Epoch 106/200\n",
            "94/94 - 123s - loss: 0.0672 - val_loss: 0.1643\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.16556 to 0.16427, saving model to model.h5\n",
            "Epoch 107/200\n",
            "94/94 - 125s - loss: 0.0651 - val_loss: 0.1626\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.16427 to 0.16257, saving model to model.h5\n",
            "Epoch 108/200\n",
            "94/94 - 125s - loss: 0.0626 - val_loss: 0.1612\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.16257 to 0.16116, saving model to model.h5\n",
            "Epoch 109/200\n",
            "94/94 - 125s - loss: 0.0601 - val_loss: 0.1608\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.16116 to 0.16084, saving model to model.h5\n",
            "Epoch 110/200\n",
            "94/94 - 125s - loss: 0.0609 - val_loss: 0.1667\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.16084\n",
            "Epoch 111/200\n",
            "94/94 - 125s - loss: 0.0663 - val_loss: 0.1647\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.16084\n",
            "Epoch 112/200\n",
            "94/94 - 125s - loss: 0.0671 - val_loss: 0.1647\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.16084\n",
            "Epoch 113/200\n",
            "94/94 - 126s - loss: 0.0604 - val_loss: 0.1602\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.16084 to 0.16019, saving model to model.h5\n",
            "Epoch 114/200\n",
            "94/94 - 125s - loss: 0.0547 - val_loss: 0.1542\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.16019 to 0.15421, saving model to model.h5\n",
            "Epoch 115/200\n",
            "94/94 - 125s - loss: 0.0508 - val_loss: 0.1523\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.15421 to 0.15227, saving model to model.h5\n",
            "Epoch 116/200\n",
            "94/94 - 126s - loss: 0.0496 - val_loss: 0.1575\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.15227\n",
            "Epoch 117/200\n",
            "94/94 - 125s - loss: 0.0495 - val_loss: 0.1531\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.15227\n",
            "Epoch 118/200\n",
            "94/94 - 126s - loss: 0.0486 - val_loss: 0.1525\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.15227\n",
            "Epoch 119/200\n",
            "94/94 - 126s - loss: 0.0462 - val_loss: 0.1496\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.15227 to 0.14964, saving model to model.h5\n",
            "Epoch 120/200\n",
            "94/94 - 124s - loss: 0.0436 - val_loss: 0.1457\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.14964 to 0.14568, saving model to model.h5\n",
            "Epoch 121/200\n",
            "94/94 - 123s - loss: 0.0403 - val_loss: 0.1455\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.14568 to 0.14548, saving model to model.h5\n",
            "Epoch 122/200\n",
            "94/94 - 123s - loss: 0.0390 - val_loss: 0.1467\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.14548\n",
            "Epoch 123/200\n",
            "94/94 - 123s - loss: 0.0409 - val_loss: 0.1476\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.14548\n",
            "Epoch 124/200\n",
            "94/94 - 122s - loss: 0.0425 - val_loss: 0.1514\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.14548\n",
            "Epoch 125/200\n",
            "94/94 - 122s - loss: 0.0435 - val_loss: 0.1521\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.14548\n",
            "Epoch 126/200\n",
            "94/94 - 123s - loss: 0.0433 - val_loss: 0.1497\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.14548\n",
            "Epoch 127/200\n",
            "94/94 - 122s - loss: 0.0417 - val_loss: 0.1478\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.14548\n",
            "Epoch 128/200\n",
            "94/94 - 123s - loss: 0.0402 - val_loss: 0.1480\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.14548\n",
            "Epoch 129/200\n",
            "94/94 - 123s - loss: 0.0383 - val_loss: 0.1459\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.14548\n",
            "Epoch 130/200\n",
            "94/94 - 122s - loss: 0.0352 - val_loss: 0.1434\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.14548 to 0.14340, saving model to model.h5\n",
            "Epoch 131/200\n",
            "94/94 - 122s - loss: 0.0332 - val_loss: 0.1469\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.14340\n",
            "Epoch 132/200\n",
            "94/94 - 122s - loss: 0.0332 - val_loss: 0.1420\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.14340 to 0.14201, saving model to model.h5\n",
            "Epoch 133/200\n",
            "94/94 - 122s - loss: 0.0352 - val_loss: 0.1475\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.14201\n",
            "Epoch 134/200\n",
            "94/94 - 122s - loss: 0.0385 - val_loss: 0.1504\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.14201\n",
            "Epoch 135/200\n",
            "94/94 - 122s - loss: 0.0385 - val_loss: 0.1466\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.14201\n",
            "Epoch 136/200\n",
            "94/94 - 123s - loss: 0.0367 - val_loss: 0.1456\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.14201\n",
            "Epoch 137/200\n",
            "94/94 - 124s - loss: 0.0341 - val_loss: 0.1421\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.14201\n",
            "Epoch 138/200\n",
            "94/94 - 135s - loss: 0.0313 - val_loss: 0.1413\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.14201 to 0.14133, saving model to model.h5\n",
            "Epoch 139/200\n",
            "94/94 - 127s - loss: 0.0309 - val_loss: 0.1436\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.14133\n",
            "Epoch 140/200\n",
            "94/94 - 122s - loss: 0.0309 - val_loss: 0.1392\n",
            "\n",
            "Epoch 00140: val_loss improved from 0.14133 to 0.13915, saving model to model.h5\n",
            "Epoch 141/200\n",
            "94/94 - 123s - loss: 0.0288 - val_loss: 0.1411\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.13915\n",
            "Epoch 142/200\n",
            "94/94 - 124s - loss: 0.0292 - val_loss: 0.1431\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.13915\n",
            "Epoch 143/200\n",
            "94/94 - 127s - loss: 0.0295 - val_loss: 0.1481\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.13915\n",
            "Epoch 144/200\n",
            "94/94 - 128s - loss: 0.0310 - val_loss: 0.1419\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.13915\n",
            "Epoch 145/200\n",
            "94/94 - 130s - loss: 0.0319 - val_loss: 0.1455\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.13915\n",
            "Epoch 146/200\n",
            "94/94 - 125s - loss: 0.0309 - val_loss: 0.1410\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.13915\n",
            "Epoch 147/200\n",
            "94/94 - 124s - loss: 0.0265 - val_loss: 0.1387\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.13915 to 0.13873, saving model to model.h5\n",
            "Epoch 148/200\n",
            "94/94 - 126s - loss: 0.0246 - val_loss: 0.1387\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.13873 to 0.13868, saving model to model.h5\n",
            "Epoch 149/200\n",
            "94/94 - 124s - loss: 0.0229 - val_loss: 0.1360\n",
            "\n",
            "Epoch 00149: val_loss improved from 0.13868 to 0.13595, saving model to model.h5\n",
            "Epoch 150/200\n",
            "94/94 - 123s - loss: 0.0216 - val_loss: 0.1369\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.13595\n",
            "Epoch 151/200\n",
            "94/94 - 126s - loss: 0.0205 - val_loss: 0.1353\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.13595 to 0.13532, saving model to model.h5\n",
            "Epoch 152/200\n",
            "94/94 - 127s - loss: 0.0207 - val_loss: 0.1359\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.13532\n",
            "Epoch 153/200\n",
            "94/94 - 128s - loss: 0.0207 - val_loss: 0.1361\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.13532\n",
            "Epoch 154/200\n",
            "94/94 - 126s - loss: 0.0208 - val_loss: 0.1358\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.13532\n",
            "Epoch 155/200\n",
            "94/94 - 123s - loss: 0.0199 - val_loss: 0.1366\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.13532\n",
            "Epoch 156/200\n",
            "94/94 - 125s - loss: 0.0205 - val_loss: 0.1441\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.13532\n",
            "Epoch 157/200\n",
            "94/94 - 123s - loss: 0.0236 - val_loss: 0.1400\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.13532\n",
            "Epoch 158/200\n",
            "94/94 - 123s - loss: 0.0242 - val_loss: 0.1403\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.13532\n",
            "Epoch 159/200\n",
            "94/94 - 123s - loss: 0.0241 - val_loss: 0.1402\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.13532\n",
            "Epoch 160/200\n",
            "94/94 - 123s - loss: 0.0247 - val_loss: 0.1445\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.13532\n",
            "Epoch 161/200\n",
            "94/94 - 122s - loss: 0.0286 - val_loss: 0.1460\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.13532\n",
            "Epoch 162/200\n",
            "94/94 - 122s - loss: 0.0289 - val_loss: 0.1424\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.13532\n",
            "Epoch 163/200\n",
            "94/94 - 122s - loss: 0.0265 - val_loss: 0.1404\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.13532\n",
            "Epoch 164/200\n",
            "94/94 - 123s - loss: 0.0235 - val_loss: 0.1395\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.13532\n",
            "Epoch 165/200\n",
            "94/94 - 123s - loss: 0.0208 - val_loss: 0.1376\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.13532\n",
            "Epoch 166/200\n",
            "94/94 - 124s - loss: 0.0182 - val_loss: 0.1341\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.13532 to 0.13409, saving model to model.h5\n",
            "Epoch 167/200\n",
            "94/94 - 123s - loss: 0.0158 - val_loss: 0.1340\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.13409 to 0.13404, saving model to model.h5\n",
            "Epoch 168/200\n",
            "94/94 - 125s - loss: 0.0146 - val_loss: 0.1332\n",
            "\n",
            "Epoch 00168: val_loss improved from 0.13404 to 0.13317, saving model to model.h5\n",
            "Epoch 169/200\n",
            "94/94 - 124s - loss: 0.0152 - val_loss: 0.1341\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.13317\n",
            "Epoch 170/200\n",
            "94/94 - 122s - loss: 0.0163 - val_loss: 0.1377\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.13317\n",
            "Epoch 171/200\n",
            "94/94 - 123s - loss: 0.0202 - val_loss: 0.1415\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.13317\n",
            "Epoch 172/200\n",
            "94/94 - 124s - loss: 0.0219 - val_loss: 0.1395\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.13317\n",
            "Epoch 173/200\n",
            "94/94 - 124s - loss: 0.0216 - val_loss: 0.1430\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.13317\n",
            "Epoch 174/200\n",
            "94/94 - 130s - loss: 0.0245 - val_loss: 0.1469\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.13317\n",
            "Epoch 175/200\n",
            "94/94 - 134s - loss: 0.0285 - val_loss: 0.1499\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.13317\n",
            "Epoch 176/200\n",
            "94/94 - 135s - loss: 0.0267 - val_loss: 0.1437\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.13317\n",
            "Epoch 177/200\n",
            "94/94 - 130s - loss: 0.0234 - val_loss: 0.1404\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.13317\n",
            "Epoch 178/200\n",
            "94/94 - 130s - loss: 0.0201 - val_loss: 0.1375\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.13317\n",
            "Epoch 179/200\n",
            "94/94 - 137s - loss: 0.0168 - val_loss: 0.1349\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.13317\n",
            "Epoch 180/200\n",
            "94/94 - 137s - loss: 0.0141 - val_loss: 0.1337\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.13317\n",
            "Epoch 181/200\n",
            "94/94 - 137s - loss: 0.0125 - val_loss: 0.1323\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.13317 to 0.13232, saving model to model.h5\n",
            "Epoch 182/200\n",
            "94/94 - 137s - loss: 0.0116 - val_loss: 0.1318\n",
            "\n",
            "Epoch 00182: val_loss improved from 0.13232 to 0.13176, saving model to model.h5\n",
            "Epoch 183/200\n",
            "94/94 - 136s - loss: 0.0121 - val_loss: 0.1342\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.13176\n",
            "Epoch 184/200\n",
            "94/94 - 135s - loss: 0.0130 - val_loss: 0.1344\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.13176\n",
            "Epoch 185/200\n",
            "94/94 - 136s - loss: 0.0124 - val_loss: 0.1331\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.13176\n",
            "Epoch 186/200\n",
            "94/94 - 136s - loss: 0.0125 - val_loss: 0.1349\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.13176\n",
            "Epoch 187/200\n",
            "94/94 - 138s - loss: 0.0146 - val_loss: 0.1374\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.13176\n",
            "Epoch 188/200\n",
            "94/94 - 135s - loss: 0.0184 - val_loss: 0.1414\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.13176\n",
            "Epoch 189/200\n",
            "94/94 - 137s - loss: 0.0207 - val_loss: 0.1411\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.13176\n",
            "Epoch 190/200\n",
            "94/94 - 136s - loss: 0.0216 - val_loss: 0.1428\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.13176\n",
            "Epoch 191/200\n",
            "94/94 - 137s - loss: 0.0234 - val_loss: 0.1473\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.13176\n",
            "Epoch 192/200\n",
            "94/94 - 136s - loss: 0.0255 - val_loss: 0.1462\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.13176\n",
            "Epoch 193/200\n",
            "94/94 - 136s - loss: 0.0274 - val_loss: 0.1450\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.13176\n",
            "Epoch 194/200\n",
            "94/94 - 137s - loss: 0.0235 - val_loss: 0.1403\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.13176\n",
            "Epoch 195/200\n",
            "94/94 - 137s - loss: 0.0194 - val_loss: 0.1372\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.13176\n",
            "Epoch 196/200\n",
            "94/94 - 137s - loss: 0.0159 - val_loss: 0.1347\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.13176\n",
            "Epoch 197/200\n",
            "94/94 - 137s - loss: 0.0127 - val_loss: 0.1337\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.13176\n",
            "Epoch 198/200\n",
            "94/94 - 138s - loss: 0.0109 - val_loss: 0.1327\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.13176\n",
            "Epoch 199/200\n",
            "94/94 - 137s - loss: 0.0099 - val_loss: 0.1326\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.13176\n",
            "Epoch 200/200\n",
            "94/94 - 138s - loss: 0.0097 - val_loss: 0.1318\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.13176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f00373c4590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lbYmDUY2sAd",
        "outputId": "47be422d-b25a-4835-f33a-6a59c2fbac1c"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
        "\t\traw_target, raw_src,test = raw_dataset[i]\n",
        "\t\tif i < 10:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('train')\n",
        "evaluate_model(model, eng_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, eng_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[Ég lét laga reiðhjólið mitt í gær], target=[I had my bicycle fixed yesterday], predicted=[i had my bicycle fixed yesterday]\n",
            "src=[Ég ætla að fletta þessu orði upp í orðabókinni], target=[Ill look up this word in the dictionary], predicted=[ill look up this word in the dictionary]\n",
            "src=[Þessi tól virðast vera gagnslaus], target=[These gadgets seem to be of no use], predicted=[these gadgets seem to be of use use]\n",
            "src=[Ég er svo þreyttur að ég nenni ekki að læra í kvöld], target=[Im so tired that I dont feel like studying tonight], predicted=[im so tired that i dont feel like studying tonight]\n",
            "src=[Hreimurinn hans bendir til að hann sé útlendingur], target=[His accent suggests he is a foreigner], predicted=[his accent suggests he is a foreigner]\n",
            "src=[Þú ættir að koma strax], target=[You should come at once], predicted=[you should come at once]\n",
            "src=[Ég afbókaði tíma með henni], target=[I canceled an appointment with her], predicted=[i canceled an appointment with her]\n",
            "src=[Gætirðu vinsamlegast talað aðeins hægar], target=[Could you speak more slowly please], predicted=[could you speak more slowly please]\n",
            "src=[Engin lifandi vera gæti lifað án lofts], target=[No living thing could live without air], predicted=[no living thing could live without air]\n",
            "src=[Jörðin er hnöttótt], target=[The earth is round], predicted=[the earth is round]\n",
            "BLEU-1: 0.736074\n",
            "BLEU-2: 0.667636\n",
            "BLEU-3: 0.627930\n",
            "BLEU-4: 0.521645\n",
            "test\n",
            "src=[Þetta er húsið sem þau bjuggu í], target=[Thats the house they lived in], predicted=[thats the house they were in]\n",
            "src=[Þú ættir að láta þrífa bílinn þinn], target=[You had better have your car washed], predicted=[you had better have your car washed]\n",
            "src=[Hættu að stara svona á mig], target=[Stop staring at me like that], predicted=[stop staring me me like that]\n",
            "src=[Hún bað hann um að koma inn í húsið sitt], target=[She asked him to come into her house], predicted=[she asked him to come into his house]\n",
            "src=[Þetta er erfitt], target=[This is difficult], predicted=[this is difficult]\n",
            "src=[Hún segir alltaf fallega hluti um hann sérstaklega þegar hann er á svæðinu], target=[She always says nice things about him especially when hes around], predicted=[she always says nice nice that especially especially wouldnt hes around]\n",
            "src=[Það er heimskulegt], target=[Its stupid], predicted=[its stupid]\n",
            "src=[Klukkan hvað skráði hún sig út af hótelinu], target=[What time did she check out of the hotel], predicted=[what time did she it check of the hotel]\n",
            "src=[Við þráum frið], target=[We long for peace], predicted=[we long for peace]\n",
            "src=[Æj vá segðu mér], target=[Come on tell me], predicted=[come on tell me]\n",
            "BLEU-1: 0.691566\n",
            "BLEU-2: 0.620721\n",
            "BLEU-3: 0.584796\n",
            "BLEU-4: 0.480740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZriVseTEMmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb6b2a2-9570-4115-8937-1cfad4b771d9"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
        "\t\traw_target, raw_src,test = raw_dataset[i]\n",
        "\t\tif i < 10:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('train')\n",
        "evaluate_model(model, eng_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, eng_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[Ég er upptekin], target=[Im busy], predicted=[im busy]\n",
            "src=[Skemmtu þér vel], target=[Have fun], predicted=[have a nice time]\n",
            "src=[Skemmtið ykkur vel], target=[Have a nice time], predicted=[have a nice time]\n",
            "src=[Hún er viðurkennd sem sérfræðingur í málvísindum], target=[She is recognized to be an expert on linguistics], predicted=[she is recognized to be an expert on linguistics]\n",
            "src=[Sjúklingarnir í þessari rannsókn samanstóðu af þrjátíu körlum og tuttugu og fimm konum], target=[The patients in this study consisted of 30 males and 25 females], predicted=[the patients in this study consisted of 30 males and 25 females]\n",
            "src=[Að borða hægar mun hjálpa þér við að finnast þú saddari], target=[Eating more slowly will help you feel fuller], predicted=[eating more slowly will help you feel fuller]\n",
            "src=[Ég flýtti mér á brautarstöðina til þess eins að komast að því að lestin var þegar farin], target=[I hurried to the station only to find that the train had already left], predicted=[i hurried to the station only to find that the train had already left]\n",
            "src=[Ég var svo fúll], target=[I was so unhappy], predicted=[i was so unhappy]\n",
            "src=[Vinsamlegast baðaðu barnið], target=[Please give the baby a bath], predicted=[please give the baby a bath]\n",
            "src=[Ég er alltaf til], target=[Im always ready], predicted=[im always ready]\n",
            "BLEU-1: 0.805251\n",
            "BLEU-2: 0.775527\n",
            "BLEU-3: 0.764592\n",
            "BLEU-4: 0.703748\n",
            "test\n",
            "src=[Ég fór í lystigarðinn í gær], target=[I went to the park yesterday], predicted=[i went to the park yesterday]\n",
            "src=[Þú munt bráðlega venjast því að tala opinberlega], target=[You will soon get used to speaking in public], predicted=[you will soon get used to speaking in public]\n",
            "src=[Mér kom ekki dúr á auga í nótt], target=[I didnt sleep a wink last night], predicted=[i didnt sleep a wink last night]\n",
            "src=[Ég komst ekki sökum úrhellisins], target=[I could not come because of the heavy rain], predicted=[i could not come because of the heavy rain]\n",
            "src=[Við erum frænkur], target=[She and I are cousins], predicted=[she and i are cousins]\n",
            "src=[Tom er prestur], target=[Tom is a pastor], predicted=[tom is a pastor]\n",
            "src=[Ég er strákur], target=[I am a boy], predicted=[i am a boy]\n",
            "src=[Það var skemmtilegt], target=[It was amusing], predicted=[it was amusing]\n",
            "src=[Mér finnst gaman að spila fótbolta], target=[I like to play soccer], predicted=[i like to play soccer]\n",
            "src=[Hún virðist þekkja okkur], target=[He seems to know us], predicted=[he seems to know us]\n",
            "BLEU-1: 0.757289\n",
            "BLEU-2: 0.723129\n",
            "BLEU-3: 0.715041\n",
            "BLEU-4: 0.651539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N1ZTHMFuA2k",
        "outputId": "9a85e03f-8e10-4214-fb2c-3f2055dbd8ca"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
        "\t\traw_target, raw_src,test = raw_dataset[i]\n",
        "\t\tif i < 10:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('train')\n",
        "evaluate_model(model, eng_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, eng_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[Af hverju ertu svona harður við hann], target=[Why are you so hard on him], predicted=[why are you so hard on him]\n",
            "src=[Það er skýr munur á milli þeirra tveggja], target=[There is a marked difference between them], predicted=[there is a marked difference between them]\n",
            "src=[Hvað ertu að lesa], target=[What are you reading], predicted=[what are you reading]\n",
            "src=[Hvað er ég að gera], target=[What am I doing], predicted=[what am i doing]\n",
            "src=[Þú ferð að því á rangan hátt], target=[Youre going about it in the wrong way], predicted=[you going about about in the wrong way]\n",
            "src=[Ekki hleypa hundinum inn], target=[Dont let the dog in], predicted=[dont let the dog in]\n",
            "src=[Þessi blekblettur næst ekki úr], target=[This ink stain will not wash out], predicted=[this ink stain will not wash out]\n",
            "src=[Það er mikilvægt að skilja að hvert land hefur sína eigin menningu], target=[It is important to understand that each country has its own culture], predicted=[it is important to to that each country own own culture]\n",
            "src=[Ég er ekkert svo hrifinn af sterkum mat], target=[I dont care too much for hot food], predicted=[i dont care much much for hot food]\n",
            "src=[Maðurinn blés reyk í andlitið á henni], target=[The man puffed smoke into her face], predicted=[the man puffed smoke into her face]\n",
            "BLEU-1: 0.751819\n",
            "BLEU-2: 0.691220\n",
            "BLEU-3: 0.657191\n",
            "BLEU-4: 0.560053\n",
            "test\n",
            "src=[Þúsund dollarar er há upphæð], target=[A thousand dollars is a large sum], predicted=[a thousand is is a large sum]\n",
            "src=[Í dag er heitasti dagur þessa árs], target=[Today is the hottest day this year], predicted=[today is the hottest day this year]\n",
            "src=[Ég er hryggur], target=[Im sad], predicted=[im sad]\n",
            "src=[Hún ráðlagði honum að hætta að vinna svona mikið], target=[She advised him to stop working so much], predicted=[she advised him to stop to so much]\n",
            "src=[það væri frábært ef ég gæti talað þrjú tungumál], target=[It would be cool if I could speak three languages], predicted=[it would be cool i i i speak three languages]\n",
            "src=[Ég hafði rangt fyrir mér], target=[I was wrong], predicted=[i was wrong]\n",
            "src=[Flugvélin hvarf fljótt úr augsýn], target=[The airplane soon went out of sight], predicted=[the airplane soon went out of sight]\n",
            "src=[Ég held að það sé kominn tími á að ég haldi smá boð], target=[I think its time for me to throw a little party], predicted=[i think its time for me to throw a little party]\n",
            "src=[Það eru mörg hótel niðri í bæ], target=[There are many hotels downtown], predicted=[there are many hotels downtown]\n",
            "src=[Ég vildi að ég gæti hjálpað þér], target=[I wish I could help you], predicted=[i wish i could help you]\n",
            "BLEU-1: 0.705206\n",
            "BLEU-2: 0.642131\n",
            "BLEU-3: 0.611938\n",
            "BLEU-4: 0.516219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAUgM0GkJsHS",
        "outputId": "e418a243-19fc-4715-a1d4-be07d3515030"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
        "\t\traw_target, raw_src,test = raw_dataset[i]\n",
        "\t\tif i < 100:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('train')\n",
        "evaluate_model(model, eng_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, eng_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[Hann vissi ekki hvað hann ætti að gera næst], target=[He didnt know what to do next], predicted=[he didnt know what to do next]\n",
            "src=[Ertu hér til að hjálpa mér], target=[Are you here to help me], predicted=[are you here to help me]\n",
            "src=[Hver ykkar getur gert það], target=[Any of you can do it], predicted=[any of you can do it]\n",
            "src=[Ég kem heim eins fljótt og ég get], target=[Ill come back home as soon as I can], predicted=[ill come back home as soon as i can]\n",
            "src=[Fuglar gera hreiður], target=[Birds build nests], predicted=[birds build nests]\n",
            "src=[Dauði hans kom okkur öllum í opna skjöldu], target=[His death surprised us all], predicted=[his death surprised us all]\n",
            "src=[Þú munt læra hvernig á að gera þetta fyrr eða síðar], target=[Youll learn how to do it sooner or later], predicted=[youll learn how to do it sooner or later]\n",
            "src=[Hvernig gerði hann það], target=[How did he do it], predicted=[how did he do it]\n",
            "src=[Chíleið brenndi mig á tungunni], target=[The chili burnt my tongue], predicted=[the chili burnt my tongue]\n",
            "src=[Nei takk Ég er bara að skoða], target=[No thank you I am just looking], predicted=[no thank you i am just looking]\n",
            "src=[Hann málaði dyrnar bláar], target=[He painted the door blue], predicted=[he painted the door blue]\n",
            "src=[Brandarinn hans var frábær], target=[His joke was great], predicted=[his joke was great]\n",
            "src=[Ég keypti snjallsíma handa konunni minni], target=[I bought a smartphone for my wife], predicted=[i bought a smartphone for my wife]\n",
            "src=[Hversvegna fórstu út], target=[Why did you go out], predicted=[why did you go out]\n",
            "src=[Þetta er strætisvagnsstöðin], target=[That is the bus stop], predicted=[that is the bus stop]\n",
            "src=[Hann skilaði inn uppsögninni sinni], target=[He handed in his resignation], predicted=[he handed in his resignation]\n",
            "src=[Hann er blindur á öðru auganu], target=[He is blind in one eye], predicted=[he is blind in one eye]\n",
            "src=[Má bjóða ykkur kaffi], target=[Would you like some coffee], predicted=[would you like some coffee]\n",
            "src=[Ég er fátæk], target=[Im poor], predicted=[im poor]\n",
            "src=[Þú hefðir átt að segja mér fyrir löngu], target=[You should have told me a long time ago], predicted=[you should have told me a long time ago]\n",
            "src=[Hann borgaði tuttugu dollara fyrir varalitinn], target=[He paid 20 for the lipstick], predicted=[he paid 20 for the lipstick]\n",
            "src=[Hikaðu ekki við að koma með tillögur], target=[Please feel free to make suggestions], predicted=[please feel free to make suggestions]\n",
            "src=[Hún keypti grænmeti í gær], target=[She bought some vegetables yesterday], predicted=[she bought some vegetables yesterday]\n",
            "src=[Ég hef það fínt], target=[Im doing great], predicted=[im doing great]\n",
            "src=[Þú verður að skila bókinni til hans], target=[You must return the book to him], predicted=[you must return the book to him]\n",
            "src=[Veturinn er uppáhalds árstíðin mín], target=[Winter is my favorite season], predicted=[winter is my favorite season]\n",
            "src=[Það var ekki alltaf svona], target=[It was not always this way], predicted=[it was not always this way]\n",
            "src=[Þú berð ábyrgð á útkomunni], target=[You are responsible for the result], predicted=[you are responsible for the result]\n",
            "src=[Er mögulegt að ákvarða þvermálið frá ummálinu], target=[Is it possible to determine the diameter from the circumference], predicted=[is it possible to determine the diameter from the circumference]\n",
            "src=[Við ætlum að klifra þetta fjall], target=[We are going to climb that mountain], predicted=[we are going to climb that mountain]\n",
            "src=[Ég fór til Evrópu einu sinni], target=[I went to Europe once], predicted=[i went to europe once]\n",
            "src=[Þau eru með mjög skemmtilega verönd], target=[They have a very nice veranda], predicted=[they have a very nice veranda]\n",
            "src=[Dómurinn hefur verið kveðinn upp], target=[The verdict is in], predicted=[the verdict is in]\n",
            "src=[Hún var döpur], target=[She felt blue], predicted=[she felt blue]\n",
            "src=[Í dag á systir mín afmæli], target=[Today is my sisters birthday], predicted=[today is my sisters birthday]\n",
            "src=[Hún hjálpaði föður sínum með verkin í garðinum], target=[She helped her father with the work in the garden], predicted=[she helped her father with the work in the garden]\n",
            "src=[Tsúbasa lestin er mjög hraðskreið], target=[The Tsubasa is a very fast train], predicted=[the tsubasa is a very fast train]\n",
            "src=[Ég er ekki fædd í gær], target=[I wasnt born yesterday], predicted=[i wasnt born yesterday]\n",
            "src=[Ég kem að hitta þig á sunnudaginn], target=[I will come to see you next Sunday], predicted=[i will come to see you next sunday]\n",
            "src=[Í því að ég var að fara út fór að rigna], target=[Just as I went to go out it began to rain], predicted=[just as i went to go out it began to rain]\n",
            "src=[Ég er orðin uppiskroppa með peninga], target=[Ive run out of money], predicted=[ive run out of money]\n",
            "src=[Maður birtist handan dyranna], target=[A man appeared from behind the door], predicted=[a man appeared from behind the door]\n",
            "src=[Ég er búin að fá nóg], target=[Ive had enough], predicted=[ive had enough]\n",
            "src=[Þú mátt leggja hérna], target=[You may park here], predicted=[you may park here]\n",
            "src=[Ég er svolítið þreytt], target=[Im feeling sort of tired], predicted=[im feeling sort of tired]\n",
            "src=[Ég kom eins fljótt og ég gat], target=[I came as fast as I could], predicted=[i came as fast as i could]\n",
            "src=[Ég hugsa að ég sé bara þreyttur], target=[I think Im just tired], predicted=[i think im just tired]\n",
            "src=[Ég vona að þú eigir góða ferð], target=[I hope you enjoy your flight], predicted=[i hope you enjoy your flight]\n",
            "src=[Hann sneri baki við gömlu hefðunum], target=[He turned his back on the old traditions], predicted=[he turned his back on the old traditions]\n",
            "src=[Hundurinn elti hann hvert sem hann fór], target=[The dog followed him wherever he went], predicted=[the dog followed him wherever he went]\n",
            "src=[Hvern skiptir það annars máli], target=[Who cares anyway], predicted=[who cares anyway]\n",
            "src=[Ertu að grínast], target=[Are you kidding], predicted=[are you kidding]\n",
            "src=[Ég er jafn gömul], target=[I am the same age], predicted=[i am the same age]\n",
            "src=[Ég slökkti á lampanum og sofnaði], target=[I turned the lamp off and fell asleep], predicted=[i turned the lamp off and fell asleep]\n",
            "src=[Vannstu vinnuna þína], target=[Did you do your work], predicted=[did you do your work]\n",
            "src=[Ekki skilja dyrnar eftir opnar], target=[Dont leave the door open], predicted=[dont leave the door open]\n",
            "src=[Ég hlýt að vera með vitlaust númer], target=[I must have the wrong number], predicted=[i must have the wrong number]\n",
            "src=[Hún ráðlagði honum að taka fyrstu lestina um morguninn], target=[She advised him to catch the first train in the morning], predicted=[she advised him to catch the first train in the morning]\n",
            "src=[Faðir minn keypti mér reiðhjól], target=[My father bought me a bicycle], predicted=[my father bought me a bicycle]\n",
            "src=[Útlendingurinn talaði japönsku eins og það væri hennar móðurmál], target=[The foreigner spoke Japanese as if it were her mother tongue], predicted=[the foreigner spoke japanese as if it were her mother tongue]\n",
            "src=[Við töluðum saman í gær], target=[We spoke yesterday], predicted=[we spoke yesterday]\n",
            "src=[Okkur veitir ekki af hjálp þína], target=[We can use your help], predicted=[we can use your help]\n",
            "src=[Ég þurfti að ganga heim], target=[I had to walk home], predicted=[i had to walk home]\n",
            "src=[Horfðu á fjallið þarna], target=[Look at that mountain], predicted=[look at that mountain]\n",
            "src=[Hún æfir sig alltaf á píanóið fyrir matinn], target=[She always practices the piano before dinner], predicted=[she always practices the piano before dinner]\n",
            "src=[Það sem hann sagði var ekki ætlað sem fullyrðing byggð á staðreyndum], target=[His remark was not intended to be a factual statement], predicted=[his remark was not intended to be a factual statement]\n",
            "src=[Við erum jafnar], target=[Were even], predicted=[were even]\n",
            "src=[Hvort er fljótlegra leigubíll eða neðanjarðarlestin], target=[Which is quicker a taxi or the subway], predicted=[which is quicker a taxi or the subway]\n",
            "src=[Þetta hús er ekki til sölu], target=[This house is not for sale], predicted=[this house is not for sale]\n",
            "src=[Lífið byrjar þegar við gerum okkur grein fyrir því hver við erum í raun og veruj], target=[Life begins when we realize who we really are], predicted=[life begins when we realize who we are are]\n",
            "src=[Hver ætli hafa byrjað þá sögusögn], target=[I wonder who started that rumor], predicted=[i wonder who started that rumor]\n",
            "src=[Mundirðu vinsamlegast hella mér kaffibolla], target=[Would you please pour me a cup of coffee], predicted=[would you please pour me a cup of coffee]\n",
            "src=[Tom kemst að því], target=[Tomll find out], predicted=[tomll find out]\n",
            "src=[Hefurðu nokkurntíma séð hann synda], target=[Have you ever seen him swimming], predicted=[have you ever seen him swimming]\n",
            "src=[Hann er fljótasti hlauparinn í bekknum okkar], target=[He is the fastest runner in our class], predicted=[he is the fastest runner in our class]\n",
            "src=[Þýskaland kom á fót velferðarkerfi á níunda áratug nítjándu aldar], target=[Germany adopted a social security system in the 1880s], predicted=[germany adopted a social security system in the 1880s]\n",
            "src=[Þvoðu þér um hendurnar], target=[Wash your hands], predicted=[wash your hands]\n",
            "src=[Nefndin samanstendur af vísindamönnum og verkfræðingum], target=[The committee consists of scientists and engineers], predicted=[the committee consists of scientists and engineers]\n",
            "src=[Dyrunum er læst klukkan níu á hverju kvöldi], target=[The door is locked at nine every night], predicted=[the door is locked at nine every night]\n",
            "src=[Við ræddum málið], target=[We discussed the matter], predicted=[we discussed the matter]\n",
            "src=[Þau hræddust þig], target=[They feared you], predicted=[they feared you]\n",
            "src=[Ég get ekki talað þýsku], target=[I cannot speak German], predicted=[i cannot speak german]\n",
            "src=[Fór hann heim í gær], target=[Did he go home yesterday], predicted=[did he go home yesterday]\n",
            "src=[Hún bað hann um að hjálpa föður sínum við að þrífa bílskúrinn], target=[She asked him to help his father clean the garage], predicted=[she asked him to help her father clean the garage]\n",
            "src=[Ég mundi heldur vilja tala við þig í einrúmi], target=[Id prefer to speak to you in private], predicted=[id prefer to speak to you in in]\n",
            "src=[Hvar er járnbrautarstöðin], target=[Where is the railway station], predicted=[where is the railway station]\n",
            "src=[Mig langar ekki í meira], target=[I dont want any more], predicted=[i dont want any more]\n",
            "src=[Við erum svöng], target=[We are hungry], predicted=[we are hungry]\n",
            "src=[Mér finnst gaman að ferðast], target=[I like traveling], predicted=[i like traveling]\n",
            "src=[Þú verður að vinna upp fyrir tapið], target=[You must make up for the loss], predicted=[you must make up for the loss]\n",
            "src=[Hefurðu einhverntíma farið á skrifstofuna þar sem pabbi þinn vinnur], target=[Have you ever visited the office where your father works], predicted=[have you ever visited the office where your father works]\n",
            "src=[Allir geta orðið vinir jafnvel þótt tungumál þeirra og siðir eru ólík], target=[All people can become friends even if their languages and customs are different], predicted=[all people can become friends even if their languages and customs are different]\n",
            "src=[Nemendurnir eru að tala um tungumál og menningu], target=[The students are talking about language and culture], predicted=[the students are talking about language and culture]\n",
            "src=[Er einhver þarna], target=[Is somebody there], predicted=[is somebody there]\n",
            "src=[Hún spurði hann hvort hann væri nemandi við þennan skóla], target=[She asked him if he was a student at this school], predicted=[she asked him if he was a student at this school]\n",
            "src=[Ég tók rútuna til að ná á áfangastað fyrir myrkur], target=[I took the bus in order to reach the destination before it got dark], predicted=[i took the bus in order to reach the destination before it got dark]\n",
            "src=[Róaðu þig], target=[Cool off], predicted=[calm down]\n",
            "src=[Snúið aftur í sætin ykkar], target=[Go back to your seat], predicted=[go back to your seat]\n",
            "src=[Hann kemur á morgun til Parísar], target=[He will arrive in Paris tomorrow], predicted=[he will arrive in paris tomorrow]\n",
            "src=[Það gera þrjú þúsund jen], target=[The total comes to 3000 yen], predicted=[the total comes to 3000 yen]\n",
            "BLEU-1: 0.804633\n",
            "BLEU-2: 0.775299\n",
            "BLEU-3: 0.764762\n",
            "BLEU-4: 0.704499\n",
            "test\n",
            "src=[Sá yðar sem syndlaus er kasti fyrsta steininum], target=[Let him who is without sin cast the first stone], predicted=[let him who is without sin cast the first stone]\n",
            "src=[Þú verður að fylgja henni heim], target=[Youve got to see her home], predicted=[youve got to see her home]\n",
            "src=[Hann svarar bréfinu þínu braðlega], target=[Hell answer your letter soon], predicted=[hell answer your letter soon]\n",
            "src=[Ég gæti haldið endalaust áfram um það en ég ætla það ekki], target=[I could go on and on about it but I wont], predicted=[i could go on and on about it but i wont]\n",
            "src=[Hann var mér reiður vegna þess að ég sagði honum upp], target=[He was mad at me because I broke up with him], predicted=[he was mad at me i i broke up with him]\n",
            "src=[Degas fæddist fyrir meira en hundrað og fimmtíu árum], target=[Degas was born more than 150 years ago], predicted=[degas was born more than 150 years ago]\n",
            "src=[Hvað langar þig í eftirrétt], target=[What would you like for dessert], predicted=[what would you like for dessert]\n",
            "src=[Ég vildi óska að það væri meiri fjölbreytni í vinnunni minni], target=[I wish there was more variety in my work], predicted=[i wish there was more variety in my work]\n",
            "src=[Ég er að leita að ákveðnum gömlum manni], target=[Im looking for a certain old man], predicted=[im looking for a certain old man]\n",
            "src=[Kassinn var tómur], target=[The box was empty], predicted=[the box was empty]\n",
            "src=[Hún hjálpaði þeim með farangurinn], target=[She lent them a hand with their luggage], predicted=[she lent them a hand with their luggage]\n",
            "src=[Áttu enn í vandræðum með eðlisfræðina], target=[Are you still having difficulty with physics], predicted=[are you still having difficulty with physics]\n",
            "src=[Ég skil ekki], target=[I dont follow], predicted=[i dont follow]\n",
            "src=[Hann var í fastasvefni], target=[He was fast asleep], predicted=[he was fast asleep]\n",
            "src=[Ég las ekki bók í gær], target=[I didnt read a book yesterday], predicted=[i didnt read a book yesterday]\n",
            "src=[Forsetinn sat í stólnum með bakið að glugganum], target=[The president was sitting in the chair with his back to the window], predicted=[the president was sitting in the chair with his back to to window]\n",
            "src=[Ég hef fleira að segja], target=[I have more to say], predicted=[i have more to say]\n",
            "src=[Enginn gat fundið hellinn], target=[No one could find the cave], predicted=[no one could find the cave]\n",
            "src=[Þetta er ekki það sem ég er að leita að], target=[That isnt what Im looking for], predicted=[that isnt what im looking for]\n",
            "src=[Hvað mundir þú gera ef þú værir í mínum sporum], target=[What would you do if you were in my place], predicted=[what would you do if you were in my place]\n",
            "src=[Það hlítur að vera hér], target=[It must be here], predicted=[it must be here]\n",
            "src=[Hann verður góður kennari], target=[He will be a good teacher], predicted=[he will be a good teacher]\n",
            "src=[Passaðu þig á Tom], target=[Look out for Tom], predicted=[look out for tom]\n",
            "src=[Minntist hún á niðurstöður prófsins], target=[Did she mention the results of the exam], predicted=[did she mention the results of the exam]\n",
            "src=[„Þú hlýtur að vera þreytt eftir langan dag“ „Nei ekki vitund“], target=[You must be tired after a long day No not in the least], predicted=[you must be tired after a long day no not in the least]\n",
            "src=[Ég sagði „Gætir þú vinsamlegast lækkað í sjónvarpinu þínu“], target=[I said Could you please turn your television down], predicted=[i said could you please turn your television down]\n",
            "src=[Sjáðu þennan], target=[Look at that one], predicted=[look at that one]\n",
            "src=[Stjórnmálaferli hans er lokið], target=[His political career has ended], predicted=[his political career has ended]\n",
            "src=[Ég mundi heldur vera heima en fara út], target=[I would rather stay home than go out], predicted=[i would rather stay home than go out]\n",
            "src=[Ég fór um borð í rangan strætisvagn], target=[I got on the wrong bus], predicted=[i got on the wrong bus]\n",
            "src=[Sumarið virðist loksins vera komið], target=[Summer seems to have come at last], predicted=[summer seems to have come at last]\n",
            "src=[Samkvæmt Biblíunni skapaði Guð heiminn á sex dögum], target=[According to the Bible God created the world in six days], predicted=[according to the bible god created the world in six days]\n",
            "src=[Ég kem fyrir tíu], target=[Ill come by 10], predicted=[ill come by 10]\n",
            "src=[Hugmyndin er mjög freistandi], target=[The idea is very attractive], predicted=[the idea is very attractive]\n",
            "src=[Geturðu greint hveiti frá byggi], target=[Can you tell wheat from barley], predicted=[can you tell wheat from barley]\n",
            "src=[Þegar halakartan stækkar hverfur halinn og fætur taka að myndast], target=[As a tadpole grows the tail disappears and legs begin to form], predicted=[as a tadpole grows the tail disappears and legs begin to]\n",
            "src=[Geturðu líka keypt eitt fyrir mig], target=[Can you buy one for me as well], predicted=[can you buy one for me as well]\n",
            "src=[Ég meiði mig enn í löppunum], target=[My legs still hurt], predicted=[my legs still hurt]\n",
            "src=[Þetta er ekki þar], target=[Its not there], predicted=[its not there]\n",
            "src=[Mér er kalt], target=[I feel cold], predicted=[i feel cold]\n",
            "src=[Enginn kom mér til hjálpar], target=[No one came to help me], predicted=[no one came to help me]\n",
            "src=[Það eru nokkrar bækur á borðinu], target=[There are some books on the desk], predicted=[there are some books on the desk]\n",
            "src=[Af hverju skyldi hann hafa gert þetta], target=[I wonder why he did that], predicted=[i wonder why he did that]\n",
            "src=[Við komum á eyjuna tveimur dögum síðar], target=[We arrived on the island two days later], predicted=[we arrived on the island two days later]\n",
            "src=[Ég var ekki þyrstur], target=[I wasnt thirsty], predicted=[i wasnt thirsty]\n",
            "src=[Hún hefur fengið góða menntun], target=[She has received a good education], predicted=[she has received a good education]\n",
            "src=[Við leituðum að því hér og þar], target=[We looked for it here and there], predicted=[we looked for it here and there]\n",
            "src=[Ég kann ekki að keyra], target=[I dont know how to drive], predicted=[i dont know how to drive]\n",
            "src=[Hann mætti í skólann þrátt fyrir að hann væri ekki hraustur], target=[He came to school even though he was unwell], predicted=[he came to school even though he was unwell]\n",
            "src=[Lokaðu dyrunum], target=[Shut the door], predicted=[shut the door]\n",
            "src=[Hann málar oft landslagsmálverk], target=[He often paints landscapes], predicted=[he often paints landscapes]\n",
            "src=[Ekki blekkja hann], target=[Dont deceive him], predicted=[dont deceive him]\n",
            "src=[Þú ættir að fá þér klippingu], target=[You should get your hair cut], predicted=[you should get your hair cut]\n",
            "src=[Ég á enga peninga en ég á mér drauma], target=[I dont have any money but I have dreams], predicted=[i dont have any money i i have]\n",
            "src=[Ég verð að leysa vandamálið á eigin spýtur], target=[I have to solve the problem myself], predicted=[i have to solve the problem myself]\n",
            "src=[Ekki trufla mig með svona kjánalegum spurningum], target=[Dont bother me with such foolish questions], predicted=[dont bother me with such foolish questions]\n",
            "src=[Gulrætur og næpur eru ætar rætur], target=[Carrots and turnips are edible roots], predicted=[carrots and turnips are edible roots]\n",
            "src=[Hversvegna fóru þau ekki], target=[Why didnt they go], predicted=[why didnt they go]\n",
            "src=[Hún leit um herbergið], target=[She looked around the room], predicted=[she looked around the room]\n",
            "src=[Ég borgaði 200 dollara í skatta], target=[I paid 200 in taxes], predicted=[i paid 200 in taxes]\n",
            "src=[Við héldum utan um öll útgjöld okkar meðan við vorum í Ástralíu], target=[We kept track of all our expenses while we were in Australia], predicted=[we kept track of all our expenses while we were in australia]\n",
            "src=[Dragið ekki dár að útlendingum], target=[Dont poke fun at foreigners], predicted=[dont poke fun at foreigners]\n",
            "src=[Ég er nemandi við Háskólann í Hjógó], target=[I am a student at Hyogo University], predicted=[i am a student at hyogo university]\n",
            "src=[Verið er að byggja nýjar byggingar hér þar og allstaðar], target=[New buildings are being built here there and everywhere], predicted=[new buildings are being built here there and everywhere]\n",
            "src=[Hann hitti markið], target=[He hit the mark], predicted=[he hit the mark]\n",
            "src=[Um hvað ertu að tala], target=[What are you talking about], predicted=[what are you talking about]\n",
            "src=[Hann er ekki með neina atvinnu Hann er sestur í helgan stein], target=[He doesnt have a job Hes retired], predicted=[he doesnt have a job hes retired]\n",
            "src=[Ég vona að þú ákveðir þig fljótt], target=[I hope youll make up your mind quickly], predicted=[i hope youll make up your mind quickly]\n",
            "src=[Það er ekki hægt að sturta niður í klósettinu], target=[The toilet doesnt flush], predicted=[the toilet doesnt flush]\n",
            "src=[Dreptu á dyrnar], target=[Knock on the door], predicted=[knock on the door]\n",
            "src=[Bað hann þín], target=[Did he propose to you], predicted=[did he propose to you]\n",
            "src=[Þú ert að fara í vitlausa átt], target=[Youre going in the wrong direction], predicted=[youre going in the wrong direction]\n",
            "src=[Taktu af þér bindið], target=[Take off your tie], predicted=[take off your tie]\n",
            "src=[Hvert ykkar kom hingað fyrst], target=[Which of you came here first], predicted=[which of you came here first]\n",
            "src=[Ég vonast til að sjá þig], target=[I hope to see you], predicted=[i hope to see you]\n",
            "src=[Ég skal sækja eitthvað að drekka fyrir ykkur bæði], target=[Ill get something to drink for both of you], predicted=[ill get something to drink for both of you]\n",
            "src=[Í hvert skipti sem sígarettur hækka í verði reyna margir að hætta að reykja], target=[Every time cigarettes go up in price many people try to give up smoking], predicted=[every time cigarettes go up in price many people try to give up smoking]\n",
            "src=[Mér líkar ekki að læra óreglulegar sagnir], target=[I dont like learning irregular verbs], predicted=[i dont like learning irregular verbs]\n",
            "src=[Ég kaupi alltaf vörur í hæsta gæðaflokki jafnvel þótt þær séu aðeins dýrari], target=[I always buy a top quality product even if it is slightly more expensive], predicted=[i always buy a top quality product even if it is slightly more expensive]\n",
            "src=[Hvaða hljóð er þetta], target=[Whats that sound], predicted=[whats that sound]\n",
            "src=[Í alvöru], target=[Really], predicted=[really]\n",
            "src=[Hún frátók herbergi], target=[She reserved a room], predicted=[she reserved a room]\n",
            "src=[Í gær rakst ég á gamlan vin minn á flugvellinum], target=[Yesterday I ran across an old friend of mine at the airport], predicted=[yesterday i ran across an old friend of mine at the airport]\n",
            "src=[Hverstu seint er það], target=[How late is it], predicted=[how late is it]\n",
            "src=[Ég hlustaði en heyrði ekki neitt], target=[I listened but I didnt hear anything], predicted=[i listened but i didnt hear anything]\n",
            "src=[Gætirðu lánað mér bókina], target=[Could you lend me the book], predicted=[could you lend me the book]\n",
            "src=[Hann trúlofaðist frænku minni], target=[He got engaged to my cousin], predicted=[he got engaged to my cousin]\n",
            "src=[Mér finnst egg vond], target=[I dislike eggs], predicted=[i dislike eggs]\n",
            "src=[Ég á tvær dætur], target=[I have two daughters], predicted=[i have two daughters]\n",
            "src=[Líkar þér japanskur matur], target=[Do you like Japanese food], predicted=[do you like japanese food]\n",
            "src=[Mundirðu fara í stórmarkaðinn að kaupa smjör], target=[Would you go to the supermarket and get some butter], predicted=[would you go to the supermarket and get some butter]\n",
            "src=[Það var stór gullstjarna á hurðinni], target=[There was a big gold star on the door], predicted=[there was a big gold star on the door]\n",
            "src=[Flýtið ykkur eða þið verðið sein], target=[Hurry up or you will be late], predicted=[hurry up or you will be late]\n",
            "src=[Vélin hans fer til Hong Kong klukkan tvö eftir hádegi], target=[His plane leaves for Hong Kong at 200 pm], predicted=[his plane leaves for hong kong at 200 pm]\n",
            "src=[Dæmið hann út frá því sem hann gerir ekki því hvernig hann lítur út], target=[Judge him by what he does not by his appearance], predicted=[judge him by what he does not by his appearance]\n",
            "src=[Mundirðu ekki frekar vilja eyða tímanum þínum í eitthvað sem þér finnst skemmtilegt], target=[Wouldnt you rather spend your time doing something you enjoy], predicted=[wouldnt you rather spend your time doing something you enjoy]\n",
            "src=[Hvernig var dansinn], target=[How was the dance], predicted=[how was the dance]\n",
            "src=[Þetta var málið], target=[That hit the spot], predicted=[that hit the spot]\n",
            "src=[Hann er rétti maðurinn í stöðuna], target=[He is the right man for the post], predicted=[he is the right man for the post]\n",
            "src=[Ég veit í alvöru ekki mikið um það], target=[I really dont know much about that], predicted=[i really dont know much about that]\n",
            "BLEU-1: 0.751182\n",
            "BLEU-2: 0.717509\n",
            "BLEU-3: 0.709925\n",
            "BLEU-4: 0.647203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1HCxsQQJFvM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(train_losses)\n",
        "plt.plot(validation_losses)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKfF-R-Z1jV0",
        "outputId": "3eac32a2-f825-4e6b-dc07-ee094bdaec99"
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        "\n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "\tprediction = model.predict(source, verbose=0)[0]\n",
        "\tintegers = [argmax(vector) for vector in prediction]\n",
        "\ttarget = list()\n",
        "\tfor i in integers:\n",
        "\t\tword = word_for_id(i, tokenizer)\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\ttarget.append(word)\n",
        "\treturn ' '.join(target)\n",
        "\n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "\tactual, predicted = list(), list()\n",
        "\tfor i, source in enumerate(sources):\n",
        "\t\t# translate encoded source text\n",
        "\t\tsource = source.reshape((1, source.shape[0]))\n",
        "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
        "\t\traw_target, raw_src,test = raw_dataset[i]\n",
        "\t\tif i < 100:\n",
        "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
        "\t\tactual.append([raw_target.split()])\n",
        "\t\tpredicted.append(translation.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('english-Icelandic-both.pkl')\n",
        "train = load_clean_sentences('english-Icelandic-train.pkl')\n",
        "test = load_clean_sentences('english-Icelandic-test.pkl')\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "# prepare german tokenizer\n",
        "ger_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "ger_vocab_size = len(ger_tokenizer.word_index) + 1\n",
        "ger_length = max_length(dataset[:, 1])\n",
        "# prepare data\n",
        "trainX = encode_sequences(ger_tokenizer, ger_length, train[:, 1])\n",
        "testX = encode_sequences(ger_tokenizer, ger_length, test[:, 1])\n",
        "\n",
        "# load model\n",
        "model = load_model('model.h5')\n",
        "# test on some training sequences\n",
        "print('train')\n",
        "evaluate_model(model, eng_tokenizer, trainX, train)\n",
        "# test on some test sequences\n",
        "print('test')\n",
        "evaluate_model(model, eng_tokenizer, testX, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "src=[Ertu í fötum], target=[Are you dressed], predicted=[are you dressed]\n",
            "src=[Við hlupum niður að árbakkanum], target=[We ran down to the riverbank], predicted=[we ran down to the riverbank]\n",
            "src=[Það gagnast þér ekkert að ræða málið frekar], target=[Discussing the matter further will get you nowhere], predicted=[discussing the matter further you you you nowhere]\n",
            "src=[Hún spurði um vinkonu sína], target=[She asked after her friend], predicted=[she asked after her friend]\n",
            "src=[Láttu þér þetta að kenningu verða], target=[Let this be an example to you], predicted=[this is be an example to you]\n",
            "src=[Ég opnaði dyrnar og sá tvo drengi standa hlið við hlið], target=[I opened the door and saw two boys standing side by side], predicted=[i opened the the and and and and side side side side]\n",
            "src=[Ekki gefast upp], target=[Dont give up], predicted=[dont give up]\n",
            "src=[Það er ekkert svar við spurningunni þinni], target=[Your question has no answer], predicted=[there question no answer to your question]\n",
            "src=[Hann er óánægður með útkomuna], target=[He is unsatisfied with the result], predicted=[he is unsatisfied with the result]\n",
            "src=[Heldurðu að hann hafi gert þessi mistök af ásettu ráði], target=[Do you think he made that mistake on purpose], predicted=[do you think he that this this purpose purpose]\n",
            "src=[Ég get ekki teiknað en systir mín er mikill listamaður], target=[I cant draw but my sister is a great artist], predicted=[i cant draw but my sister is a great artist]\n",
            "src=[Hann hitti markið], target=[He hit the mark], predicted=[he hit the mark]\n",
            "src=[Hún spurði hann af hverju hann væri að gráta en hann vildi ekki svara], target=[She asked him why he was crying but he didnt answer], predicted=[she asked him him he he he but he didnt didnt answer]\n",
            "src=[Hví reynirðu ekki að haga þér eins og herramaður], target=[Why dont you try to behave like a gentleman], predicted=[why dont you try to behave like a gentleman]\n",
            "src=[Við hlupum niður hæðina], target=[We ran down the hill], predicted=[we ran down the hill]\n",
            "src=[Við höfum ekki tíma], target=[We dont have time], predicted=[we dont have time]\n",
            "src=[Það tekur okkur þrjátíu mínútur að ganga héðan á stöðina], target=[It takes us thirty minutes to walk from here to the station], predicted=[it takes us thirty minutes walk walk smoking to to the station]\n",
            "src=[Faðir minn keypti mér reiðhjól], target=[My father bought me a bicycle], predicted=[my father bought me a bicycle]\n",
            "src=[Ég hef ekki tíma til að vera veikur], target=[I dont have time to be sick], predicted=[i dont not not to be sick]\n",
            "src=[Ég er með mikið af blómum Sum eru rauð og sum eru gul], target=[I have a lot of flowers Some are red and some are yellow], predicted=[i have a lot of of some are and and some some yellow]\n",
            "src=[Við sáum hana koma inn í herbergið], target=[We saw her enter the room], predicted=[we saw left the the room]\n",
            "src=[Hann var að koma], target=[He just arrived], predicted=[he was arrived]\n",
            "src=[Það er gat í frakkanum mínum], target=[Theres a hole in my coat], predicted=[theres a hole in my coat]\n",
            "src=[Þau segja stóra stíflu verða byggða], target=[They say that a large dam will be built], predicted=[they who a a large dam will be built]\n",
            "src=[Hún bauð honum á stefnumót en hann sagði nei vegna þess að hann taldi að stelpur ættu ekki að bjóða strákum á stefnumót], target=[She asked him out on a date but he said no since he thought girls should not ask boys out], predicted=[she asked him to out date date but but said said he he he girls girls girls girls boys boys]\n",
            "src=[Hún ráðlagði honum gegn því], target=[She advised him against doing it], predicted=[she advised him against against it]\n",
            "src=[Það er fáránlegt], target=[Thats just absurd], predicted=[thats just absurd]\n",
            "src=[Ég beraði henni sál mína], target=[I bared my soul to her], predicted=[i bared my soul to her]\n",
            "src=[Við þráum frið], target=[We long for peace], predicted=[we long for peace]\n",
            "src=[Það er ókey], target=[Its OK], predicted=[its ok]\n",
            "src=[Ég elska hann meira en nokkuð annað], target=[I love him more than anything], predicted=[i love him more than anything]\n",
            "src=[Mig langar til að segja þér nokkuð undarlegt], target=[I want to tell you a strange thing], predicted=[i want to you you a strange thing]\n",
            "src=[Veriði komin heim fyrir sex], target=[Come home before six], predicted=[come home before six]\n",
            "src=[Hún var nógu snjöll til að láta hann ekki blekkja sig], target=[She was clever enough not to be deceived by him], predicted=[she was clever to to to deceived deceived by him]\n",
            "src=[Hún bað hann um að lesa það fyrir sig], target=[She asked him to read it for her], predicted=[she asked him to me she her her]\n",
            "src=[Hefurðu skilað skýrslunni þinni], target=[Have you sent in your report], predicted=[have you sent in your report]\n",
            "src=[Hann vinnur ekki Hann er farinn á eftirlaun], target=[He doesnt have a job Hes retired], predicted=[he doesnt have a job hes retired]\n",
            "src=[Hún ráðlagði honum að keyra ekki of hratt en hann vildi ekki hlusta], target=[She advised him not to drive too fast but he wouldnt listen to her], predicted=[she advised him not to drive fast fast but he he wouldnt to her]\n",
            "src=[Mér kom ekki dúr á auga í nótt], target=[I didnt sleep a wink last night], predicted=[i didnt sleep a wink last night]\n",
            "src=[Ég er svo þreytt að ég nenni ekki að læra í kvöld], target=[Im so tired that I dont feel like studying tonight], predicted=[im am tired that i dont feel like studying tonight]\n",
            "src=[Hikaðu ekki við að koma með tillögur], target=[Please feel free to make suggestions], predicted=[please feel free to make suggestions]\n",
            "src=[Þú munt geta keyrt bíl eftir nokkra daga], target=[Youll be able to drive a car in a few days], predicted=[you be to to to a a in a few days]\n",
            "src=[Hún ráðleggur honum um tæknileg mál], target=[She advises him on technical matters], predicted=[she advises him on technical matters]\n",
            "src=[Strákurinn fór a gráta], target=[The boy began to cry], predicted=[the boy began to cry]\n",
            "src=[Ég elska þessa mynd], target=[I love this photo], predicted=[i love this photo]\n",
            "src=[Hún hreykir sér að hún sé góður kokkur], target=[She boasts that shes good at cooking], predicted=[she boasts not shes good at cooking cooking]\n",
            "src=[Hvert er herbergisnúmerið mitt], target=[What is my room number], predicted=[my is my number]\n",
            "src=[Hún er vön að læra heima fyrir matinn], target=[She is accustomed to doing her homework before dinner], predicted=[she is accustomed to to homework homework before dinner]\n",
            "src=[Við lékum körfubolta í gær], target=[We played basketball yesterday], predicted=[we played basketball yesterday]\n",
            "src=[Tom á tvo bræður sem búa í Boston], target=[Tom has two brothers who live in Boston], predicted=[tom has the brothers who live in boston]\n",
            "src=[Þegar einhver talar með svo miklum málskrúð fer viðkomandi að hljóma sem hann sé að ljúga], target=[When someone speaks with such rhetorical flourish it starts to sound like theyre lying], predicted=[when someone speaks we rhetorical rhetorical flourish flourish starts sound sound sound theyre lying]\n",
            "src=[Má ég opna dós], target=[May I open a can], predicted=[may i open a can]\n",
            "src=[Ísinn mun brotna undan þunga okkar], target=[The ice will crack beneath our weight], predicted=[the ice will crack beneath our weight]\n",
            "src=[Það er ekki gott að lesa í dimmu herbergi], target=[Its not good to read in a dark room], predicted=[its not to to in in a dark room]\n",
            "src=[Gleðilegt nýtt ár], target=[Happy New Year], predicted=[happy new year]\n",
            "src=[Þú hefur val á milli súpu eða salats], target=[You have the choice of soup or salad], predicted=[you have the choice of soup or salad]\n",
            "src=[Horfðu á mig þegar ég tala við þig], target=[Look at me when I talk to you], predicted=[look a me chance i talk to you]\n",
            "src=[Þú getur sjálfur sagt Tom það], target=[You can tell Tom yourself], predicted=[you can tell tom yourself]\n",
            "src=[Þeir eru leikarar], target=[They are actors], predicted=[they are actors]\n",
            "src=[Hún sakaði mig um að vera lygari], target=[She accused me of being a liar], predicted=[she accused me of being a liar]\n",
            "src=[Ég bauð henni í bíó], target=[I invited her to go to the movies], predicted=[i invited her to to to]\n",
            "src=[Hún ráðlagði honum að minnka reykingarnar], target=[She advised him to cut down on smoking], predicted=[she advised him to cut on on smoking]\n",
            "src=[Gerðu það samt], target=[Do it anyway], predicted=[do it anyway]\n",
            "src=[Settu það vinsamlegast á vigtina], target=[Please put it on the scale], predicted=[please put it on the scale]\n",
            "src=[Gætirðu endurtekið þetta], target=[Could you repeat that], predicted=[could you repeat that]\n",
            "src=[Þú ættir að vita betur en að spurja dömu að aldri], target=[You should know better than to ask a lady her age], predicted=[you should not better better to something lady lady her age]\n",
            "src=[Ég er örvhentur], target=[Im lefthanded], predicted=[im lefthanded]\n",
            "src=[Hún ráðlagði honum hvað hann ætti að gera], target=[She advised him about what to do], predicted=[she advised him what what what do]\n",
            "src=[Sá sem krefst mikils fær mikið Sá sem krefst of mikils fær ekki neitt], target=[The one who demands much gets much The one who demands too much gets nothing], predicted=[the one who demands much much much much one demands demands too too too]\n",
            "src=[Hvað kallast þetta blóm], target=[What do you call this flower], predicted=[what do you call this flower]\n",
            "src=[Hver sagði Tom það], target=[Who told Tom that], predicted=[who told tom that]\n",
            "src=[Byrjum], target=[Lets begin], predicted=[lets begin]\n",
            "src=[Mundirðu vinsamlegast senda mér pöntunarlista í pósti], target=[Would you please send me a catalogue by mail], predicted=[would you please send me me catalogue by mail]\n",
            "src=[Ég hjálpaði pabba mínum í gær], target=[I helped my father yesterday], predicted=[i helped my father yesterday]\n",
            "src=[Húsgögnin eru í eigu móður minnar], target=[The furniture belongs to my mother], predicted=[the furniture belongs to my mother]\n",
            "src=[Farðu beint niður eftir götunni og þegar þú ferð framhjá umferðarljósunum ertu komin], target=[Go straight down the road and when you pass the traffic light youre there], predicted=[go straight the the the the the when pass the traffic light light there]\n",
            "src=[Mundirðu vinsamlegast gera mér greiða], target=[Would you please do me a favor], predicted=[would you please me me a favor]\n",
            "src=[Neyðin kennir naktri konu að spinna], target=[Necessity is the mother of invention], predicted=[necessity is the of of invention]\n",
            "src=[Takk fyrir daginn], target=[Thank you for today], predicted=[thank you for today]\n",
            "src=[Kennarinn tók þátt í leikjum barnanna], target=[The teacher took part in the childrens games], predicted=[the teacher took part in the childrens games]\n",
            "src=[Það keyrði bíll framhjá í myrkrinu], target=[A car passed by in the dark], predicted=[a car passed by in the dark]\n",
            "src=[Ég leit á hann sem besta lækninn í bænum], target=[I regarded him as the best doctor in town], predicted=[i regarded him the the house house in town]\n",
            "src=[Ekki leyfa neinum að koma nálægt eldinum], target=[Dont let anyone come near the fire], predicted=[dont let anyone come near the station]\n",
            "src=[Taktu eins mikið og þú vilt], target=[Take as much as you like], predicted=[a as as as you like]\n",
            "src=[Í Singapúr er það glæpur að skyrpa á jörðina], target=[In Singapore it is a crime to spit on the ground], predicted=[no singapore is to crime crime to spit on the ground]\n",
            "src=[Bankinn lánaði honum 500 dollara], target=[The bank lent him 500 dollars], predicted=[the bank lent him 500 dollars]\n",
            "src=[Hana syfjaði eftir kvöldmatinn], target=[She became drowsy after supper], predicted=[she became drowsy after supper]\n",
            "src=[Það gleður mig að heyra það], target=[Im glad to hear that], predicted=[im glad to hear that]\n",
            "src=[Mér þykir fyrir því], target=[Im sorry], predicted=[im sorry]\n",
            "src=[Hvernig bjóstu það til], target=[How did you do it], predicted=[how did you make it]\n",
            "src=[Ég skal sjá hvað ég get gert], target=[Ill see what I can do], predicted=[ill ask what i can do]\n",
            "src=[Það er köttur í eldhúsinu], target=[There is a cat in the kitchen], predicted=[there is a cat in the kitchen]\n",
            "src=[Þessi stóll er of lágur fyrir mig], target=[This chair is too low for me], predicted=[this chair is too low for me]\n",
            "src=[Hún og vinir hennar elska tónlist], target=[She and her friends love music], predicted=[she loves her friends love music]\n",
            "src=[Hvernig kynntist þú honum], target=[How did you get to know him], predicted=[how did you get to to him]\n",
            "src=[Fólki líður best þegar það er heima hjá sér], target=[People feel most at ease when they are at home], predicted=[people had most at ease when when they at home]\n",
            "src=[Mig langar að panta viðtal fyrir þriggja ára gamlan son minn], target=[Id like to make an appointment for my threeyearold son], predicted=[id want to make appointment appointment for my threeyearold]\n",
            "src=[Lestu eins margar bækur og mögulegt er], target=[Read as many books as possible], predicted=[read as many books as possible]\n",
            "src=[Hann hlýtur að vera brjálaður að gera svona lagað], target=[He must be crazy to do such a thing], predicted=[he must be crazy to such such a thing]\n",
            "src=[Taktu dyrnar úr lás], target=[Unlock the door], predicted=[unlock the door]\n",
            "BLEU-1: 0.708533\n",
            "BLEU-2: 0.624636\n",
            "BLEU-3: 0.575325\n",
            "BLEU-4: 0.459304\n",
            "test\n",
            "src=[Takk fyrir allt], target=[Thanks for everything], predicted=[thanks for everything]\n",
            "src=[Þú ert góður að elda], target=[You are a good cook], predicted=[you are a good cook]\n",
            "src=[Það var hrollur í mér þrátt fyrir að ég sæti í sólinni], target=[Even though I was sitting in the sun I still felt chilly], predicted=[even though i was the the the sun i i felt chilly]\n",
            "src=[Það er ekki að ég hafi ekki samúð með þér en ég get ekki hjálpað þér], target=[Its not that I am unsympathetic but I am not able to help you], predicted=[its not not i i unsympathetic unsympathetic am am i able to to you]\n",
            "src=[Tom hefur gaman af því að spila hafnabolta], target=[Tom likes to play baseball], predicted=[tom likes to play baseball]\n",
            "src=[Hann er hræddur við að synda], target=[He is afraid to swim], predicted=[he is afraid to swim]\n",
            "src=[Ég ákvað mig], target=[I made my decision], predicted=[i made my decision]\n",
            "src=[Það er mikilvægt að ná samstöðu eins margra verkamanna og mögulegt er], target=[Its important to unite as many workers as possible], predicted=[its important important unite as many workers as possible]\n",
            "src=[það væri frábært ef ég gæti talað þrjú tungumál], target=[It would be cool if I could speak three languages], predicted=[it would be if if could could speak three languages]\n",
            "src=[Hvar er skólinn þinn], target=[Where is your school], predicted=[where is your school]\n",
            "src=[Ég get synt], target=[Im able to swim], predicted=[i can swim]\n",
            "src=[Ég hafði enga hugmynd hvers ég ætti til bragðs að taka], target=[I had no idea what to do], predicted=[i had no idea what to do]\n",
            "src=[Þetta te kallast grænt te], target=[This tea is called green tea], predicted=[this tea is called green tea]\n",
            "src=[Hún söng ansi vel], target=[She sang pretty well], predicted=[she sang pretty well]\n",
            "src=[Hversu há ertu], target=[How tall are you], predicted=[how tall are you]\n",
            "src=[Ég mundi heldur svelta en vinna undir honum], target=[I would rather starve than work under him], predicted=[i would rather starve than him him him]\n",
            "src=[Komdu þér niður], target=[Get down], predicted=[get down]\n",
            "src=[Þeir sem nota gaffla eða matarprjóna halda oft að fólk sem gerir það ekki sé ósiðað], target=[Those who use forks or chopsticks often think people who dont are uncivilized], predicted=[those use use forks or chopsticks often often think who who uncivilized uncivilized]\n",
            "src=[Dyrnar opnuðust hægt], target=[The door opened slowly], predicted=[the door opened slowly]\n",
            "src=[Mig langar til að sýna þér stórfenglegt útsýni], target=[I want to show you a spectacular view], predicted=[i want to you you a spectacular view]\n",
            "src=[Það var næstum því keyrt á hana af hjóli], target=[She was nearly hit by a bicycle], predicted=[she was nearly hit by a bicycle]\n",
            "src=[Þessi maður er mjög mjög gamall], target=[This man is very very old], predicted=[this man is very very old]\n",
            "src=[Hún er með lífræna efnafræði sem aðalfag], target=[She majors in organic chemistry], predicted=[she majors in organic chemistry]\n",
            "src=[Móðirin lagði barnið sitt varlega í rúmið], target=[The mother laid her baby on the bed softly], predicted=[the mother laid her baby on the bed softly]\n",
            "src=[Ég skal kaupa handa þér bjór], target=[Ill buy you a beer], predicted=[ill buy you a beer]\n",
            "src=[Ég hafði búist við honum á fundinn], target=[I had expected him at the meeting], predicted=[i had expected him the the meeting]\n",
            "src=[Það er frábært], target=[Its wonderful], predicted=[its wonderful]\n",
            "src=[Þetta er strætisvagnsstöðin], target=[That is the bus stop], predicted=[that is the bus stop]\n",
            "src=[Þú þarft ekki að tala svona harkalega til mín], target=[You dont have to use such a harsh tone with me], predicted=[you dont have to to such harsh harsh tone with me]\n",
            "src=[Tom keyrði burt], target=[Tom drove away], predicted=[tom drove away]\n",
            "src=[Hann er kjarkaður], target=[He has guts], predicted=[he has guts]\n",
            "src=[Ég fer þótt svo það rigni á morgun], target=[I will go even if it rains tomorrow], predicted=[i go go even even if rains tomorrow]\n",
            "src=[Það var eina færa leiðin], target=[It was the only way to go], predicted=[it was the only way to go]\n",
            "src=[Það kom á óvart], target=[It was a surprise], predicted=[it was a surprise]\n",
            "src=[Enginn getur neitað því að enginn er reykur á elds], target=[No one can deny the fact that there is no smoke without fire], predicted=[no one no deny the fact fact there is no no without fire]\n",
            "src=[Mér er létt], target=[I feel relieved], predicted=[i feel relieved]\n",
            "src=[Ekki bera börnin þín saman við börn annarra], target=[Dont compare your children with others], predicted=[dont compare your children with others]\n",
            "src=[Ég fór hjá húsinu hennar í gær], target=[I passed by her house yesterday], predicted=[i passed by her yesterday yesterday]\n",
            "src=[Hún ráðlagði honum hvaða bækur hann ætti að kaupa], target=[She advised him on which book to buy], predicted=[she advised him to which book to to]\n",
            "src=[Gleymdu ekki að loka dyrunum áður en þú ferð], target=[Dont forget to lock the door when you leave], predicted=[dont forget the lock the when when leave leave]\n",
            "src=[Það þýðir ekki neitt], target=[It doesnt mean anything], predicted=[it doesnt mean anything]\n",
            "src=[Þau rifust], target=[They quarreled], predicted=[they quarreled]\n",
            "src=[Um hvern ertu að tala], target=[Who are you talking about], predicted=[who are you talking about]\n",
            "src=[Hættu að láta þig dreyma], target=[Stop dreaming], predicted=[stop dreaming]\n",
            "src=[Þú verður að gera það sjálf], target=[You must do it yourself], predicted=[you must do it yourself]\n",
            "src=[Ekki hlusta á hana], target=[Dont listen to her], predicted=[dont listen to her]\n",
            "src=[Tökumst í hendur], target=[Lets shake hands], predicted=[lets shake hands]\n",
            "src=[Ég næ þessu ekki], target=[I dont get it], predicted=[i dont get it]\n",
            "src=[Þú getur farið hvora leiðina sem er], target=[You can take either road], predicted=[you can take either road]\n",
            "src=[Hann getur hlaupið hraðar en ég], target=[He can run faster than I can], predicted=[he can faster faster than can can]\n",
            "src=[Allt er uppselt], target=[Everythings sold out], predicted=[everythings sold out]\n",
            "src=[Við erum systkinabörn], target=[Were cousins], predicted=[we cousins]\n",
            "src=[Enginn er reykur án elds], target=[There is no smoke without fire], predicted=[there is no smoke without fire]\n",
            "src=[Ég er svöng], target=[Im hungry], predicted=[im hungry]\n",
            "src=[Faðir minn er mér reiður], target=[Father is angry with me], predicted=[my is angry with me]\n",
            "src=[Áttu barnabörn], target=[Do you have grandchildren], predicted=[do you have grandchildren]\n",
            "src=[Ég er of þreyttur til að hlaupa], target=[I am too tired to run], predicted=[i am too tired to run]\n",
            "src=[Gömlu húsin voru rifin til að rýma fyrir stórmarkaði], target=[The old houses were torn down to make room for a supermarket], predicted=[the the houses were torn torn to to room for a supermarket]\n",
            "src=[Hvaða ástæða er fyrir þessari lygi], target=[What is the reason for that lie], predicted=[what is the reason for that lie]\n",
            "src=[Við hrærðumst svo að við táruðumst], target=[We were moved to tears], predicted=[we were moved to tears]\n",
            "src=[Hér kemur strætó], target=[Here comes the bus], predicted=[here comes the bus]\n",
            "src=[Hvað kallarðu mann sem gætir fjár í haga], target=[What do you call a man who takes care of sheep in the field], predicted=[what do you call a man who takes care sheep sheep in the field]\n",
            "src=[Hann er ennþá reiður], target=[He is still angry], predicted=[he is still angry]\n",
            "src=[Stattu á fætur], target=[Stand up], predicted=[stand up]\n",
            "src=[Ertu meðvitaður um það hversu mikið hún elskar þig], target=[Are you aware of how much she loves you], predicted=[are you aware of how how she loves you]\n",
            "src=[Ég þurfti að hlaupa á brautarstöðina], target=[I had to run to the station], predicted=[i had to to to the station]\n",
            "src=[Þetta fjall er hulið snjó allt árið um kring], target=[This mountain is covered in snow all year round], predicted=[this mountain is covered in snow all year round]\n",
            "src=[Það er enginn tími í dag], target=[Theres no class today], predicted=[theres no class today]\n",
            "src=[Hann er maður fárra orða], target=[He is a man of few words], predicted=[he is a man a few words]\n",
            "src=[Hvaða afsökun muntu nota ef þú getur ekki staðið við loforðið þitt], target=[If you cant keep your promise what excuse will you make], predicted=[if you keep keep what promise excuse excuse make you make]\n",
            "src=[Í dag á ég sextán ára afmæli], target=[Today is my sixteenth birthday], predicted=[today is my sixteenth birthday]\n",
            "src=[Hjartað er vöðvi], target=[The heart is a muscle], predicted=[the heart is a muscle]\n",
            "src=[Tom hafði rétt fyrir sér], target=[Tom was correct], predicted=[tom was correct]\n",
            "src=[Við leyfum Tom að reyna], target=[Well let Tom try], predicted=[well let tom try]\n",
            "src=[Ég var mjög hamingjusöm], target=[I felt very happy], predicted=[i felt very happy]\n",
            "src=[Þetta var nóg], target=[That was enough], predicted=[that was enough]\n",
            "src=[Er það nærri húsinu þínu], target=[Is it near your house], predicted=[is is near your house]\n",
            "src=[Fyrir hvaða manneskju finnst þér skemmtilegast að elda], target=[Whos your favorite person to cook for], predicted=[whos your favorite person to to for]\n",
            "src=[Svona er hún bara], target=[That is just her way], predicted=[that is just her way]\n",
            "src=[Forsetinn tilkynnti að Bandaríkin myndu setja gervihnött á braut um jörðu], target=[The president announced that the United States would put a satellite into orbit], predicted=[the president announced of the the states states would of satellite into orbit orbit]\n",
            "src=[Ég skar grein af trénu], target=[I cut a branch from the tree], predicted=[i cut a branch from the tree]\n",
            "src=[Taktu þessa aspirín], target=[Take this aspirin], predicted=[take this aspirin]\n",
            "src=[Hvor þessara tveggja er þyngri], target=[Which is the heavier of the two], predicted=[which is the heavier of the two]\n",
            "src=[Upphaf alheimsins verður líklega aldrei útskýrt], target=[The origin of the universe will probably never be explained], predicted=[the origin the the universe probably probably never be explained]\n",
            "src=[Hún missti af tækifærinu til að sjá fræga söngvarann], target=[She missed her chance to see the famous singer], predicted=[she missed her chance chance to the famous singer]\n",
            "src=[Ég er alltaf til], target=[Im always ready], predicted=[im always ready]\n",
            "src=[Við erum hér með börnunum okkar], target=[Were here with our children], predicted=[were here with our children]\n",
            "src=[Virkilega], target=[Really], predicted=[really]\n",
            "src=[Afsakið en ég er ekki með neina smámynt], target=[Im sorry I dont have change], predicted=[im sorry i dont have change]\n",
            "src=[Ertu góður á skíðum], target=[Can you ski well], predicted=[can you ski well]\n",
            "src=[Hún er þrjátíu og eins árs gömul], target=[She is thirtyone], predicted=[she is thirtyone]\n",
            "src=[Það var ekki alltaf svona], target=[It was not always this way], predicted=[it doesnt not always this way]\n",
            "src=[Hann gat ekki svarað þeirri spurningu], target=[He could not answer that question], predicted=[he could not answer that]\n",
            "src=[Setjumst niður og náum andanum], target=[Lets sit down and catch our breath], predicted=[lets sit down and catch our breath]\n",
            "src=[Veistu hver hann er], target=[Do you know who he is], predicted=[do you know he he is]\n",
            "src=[Ég kem aftur eftir um það bil klukkutíma], target=[Ill be back in an hour or so], predicted=[ill be back in an hour or so]\n",
            "src=[Hún er í megrunarkúr], target=[She is on a diet], predicted=[she is on a diet]\n",
            "src=[Það var sniðugt hjá honum að taka ekki þátt í því], target=[He was wise not to participate in it], predicted=[he was wise not to participate in it]\n",
            "src=[Fljúgum flugdreka], target=[Lets fly a kite], predicted=[lets fly a kite]\n",
            "src=[Förum á ströndina], target=[Lets go to the beach], predicted=[lets go to the beach]\n",
            "BLEU-1: 0.556052\n",
            "BLEU-2: 0.471029\n",
            "BLEU-3: 0.437509\n",
            "BLEU-4: 0.335381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}